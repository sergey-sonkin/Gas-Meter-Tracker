{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aPZLBLT-mOD"
      },
      "source": [
        "# Sergey Sonkin Final Project"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sz3XHFVc-ykV",
        "outputId": "0e2065fa-2a0e-4711-b4d9-d1800e31b030"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUCPFOU0-mOG"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.models import Sequential \n",
        "from keras.layers import Dense, Dropout, Flatten \n",
        "from keras.layers import Conv2D, MaxPooling2D \n",
        "from keras.layers import Input\n",
        "from keras.models import Model\n",
        "from keras import backend as K \n",
        "import numpy as np\n",
        "datadir= r\"./drive/MyDrive/16th Grade/Final/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVzUHNP--mOH"
      },
      "source": [
        "# Part 1\n",
        "## a) Importing data, showing histograms\n",
        "\n",
        "### Importing data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z7SFKpg0-mOI"
      },
      "outputs": [],
      "source": [
        "def get_fivedigit_data(shuffle=False):\n",
        "    ## Getting data out of the directory\n",
        "    data = np.float64(np.load(datadir+'data/gas_data.npy'))/255.\n",
        "    labels = np.float32(np.load(datadir+'data/gas_labels.npy'))\n",
        "    n = data.shape[0]\n",
        "    ## Shuffling data\n",
        "    if shuffle:\n",
        "        order = np.random.permutation(n)\n",
        "        data = data[order]\n",
        "        labels = labels[order]\n",
        "    ## Splitting data\n",
        "    train_data = data[0:n//2].reshape((-1,85,195))\n",
        "    train_labels = np.int32(labels[0:n//2])\n",
        "    val_data = data[n//2:n*3//5].reshape((-1,85,195))\n",
        "    val_labels = np.int32(labels[n//2:n*3//5])\n",
        "    test_data = data[n*3//5:n].reshape((-1,85,195)) \n",
        "    test_labels = np.int32(labels[n*3//5:n])\n",
        "    ## Formatting data for keras\n",
        "    img_rows, img_cols = 85,195\n",
        "    if K.image_data_format() == 'channels_first': \n",
        "        x_train = train_data.reshape(train_data.shape[0], 1, img_rows, img_cols) \n",
        "        x_val = val_data.reshape(val_data.shape[0], 1, img_rows, img_cols) \n",
        "        x_test = test_data.reshape(test_data.shape[0], 1, img_rows, img_cols) \n",
        "        input_shape = (1, img_rows, img_cols) \n",
        "    else: \n",
        "        x_train = train_data.reshape(train_data.shape[0], img_rows, img_cols, 1) \n",
        "        x_val = val_data.reshape(val_data.shape[0], img_rows, img_cols, 1) \n",
        "        x_test = test_data.reshape(test_data.shape[0], img_rows, img_cols, 1) \n",
        "        input_shape = (img_rows, img_cols, 1) \n",
        "\n",
        "    x_train = x_train.astype('float32') \n",
        "    x_val = x_val.astype('float32') \n",
        "    x_test = x_test.astype('float32') \n",
        "\n",
        "    y_train = keras.utils.to_categorical(train_labels, 10) \n",
        "    y_val = keras.utils.to_categorical(val_labels, 10) \n",
        "    y_test = keras.utils.to_categorical(test_labels, 10)\n",
        "    \n",
        "    return (x_train,y_train),(x_val,y_val),(x_test,y_test),input_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQczUpMo-mOJ"
      },
      "source": [
        "### Examining histograms\n",
        "\n",
        "The results are below. \n",
        "\n",
        "What we observe is\n",
        "\n",
        "1. The first digit is always 6 and it's not worth trying to predict it with our model. We can just treat it as predicting 6 every time which will have 100% accuracy.\n",
        "2. The second digit is just a binary classification between 1 and 2. If we wanted to be super efficient about our model we could have our model for that digit just be a binary classification model instead of a prediction on 10 numbers\n",
        "3. Digits 3 through 5 seem to be more uniform in nature, with the uniformity obviously increasing as we go towards the last digits because they change the most often."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "kzickqu_-mOJ",
        "outputId": "d3734e5f-57e3-4141-e228-b52f98f632f1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGdCAYAAAAMm0nCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAuC0lEQVR4nO3df1RVdb7/8dcRPSDGD9HgwI2QnDv+xt8RVqZXB0RypqW3X1qamlYLLWUypUzRxjAtsymz64xmc8ObtW5ZWWOilVhiGnbyZ1RGYSMH+qGc1OLn+f4xX/d0rqJChw4feD7W2mud/fl89t7v3anFq70/ex+bx+PxCAAAwCCt/F0AAABAfRFgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGae3vAhpLbW2tjh49qpCQENlsNn+XAwAALoDH49EPP/ygmJgYtWpV93WWZhtgjh49qtjYWH+XAQAAGuDIkSO65JJL6uxvtgEmJCRE0j//AYSGhvq5GgAAcCHcbrdiY2Otv+N1abYB5vRto9DQUAIMAACGOd/0DybxAgAA4xBgAACAcQgwAADAOM12DgwAwGwej0fV1dWqqanxdynwoYCAALVu3foXv+KEAAMAaHIqKytVUlKiU6dO+bsUNILg4GBFR0fLbrc3eB8EGABAk1JbW6uioiIFBAQoJiZGdrudF5I2Ex6PR5WVlfrmm29UVFSkf//3fz/ny+rOhQADAGhSKisrVVtbq9jYWAUHB/u7HPhY27Zt1aZNG3311VeqrKxUUFBQg/ZTr9iTnZ2tgQMHKiQkRJGRkbruuutUWFjoNeann35Senq6OnTooIsuukhjxoxRaWmp15ji4mKlpaUpODhYkZGRmjVrlqqrq73GvPvuu+rXr58CAwP1m9/8RmvXrm3QCQIAzNTQ/zNH0+eL77Zee9i2bZvS09O1c+dO5ebmqqqqSsnJyTp58qQ1ZubMmXr99df10ksvadu2bTp69KhGjx5t9dfU1CgtLU2VlZXasWOHnnvuOa1du1bz5s2zxhQVFSktLU1Dhw6V0+nUjBkzdPvtt+utt976xScMAACaAc8vUFZW5pHk2bZtm8fj8XiOHz/uadOmjeell16yxhw6dMgjyZOfn+/xeDyeN99809OqVSuPy+WyxqxcudITGhrqqaio8Hg8Hs99993n6dGjh9exbrzxRk9KSsoF11ZeXu6R5CkvL2/w+QEAfn0//vij5+DBg54ff/zR36X41DvvvOOR5Dl27FidY+bPn+/p3bt3vfddVFTkkeT56KOP6rVdXFyc5/HHH7fWJXleeeWVC97+Qs7pbM71HV/o3+9fNAemvLxckhQRESFJKigoUFVVlYYPH26N6dq1qy699FLl5+friiuuUH5+vnr16qWoqChrTEpKiu666y4dOHBAffv2VX5+vtc+To+ZMWNGnbVUVFSooqLCWne73b/k1AAATVCnOW/8asf6cnHaBY893yTj+fPna8iQIefdz7333qvp06df8HF9raSkRO3bt7/g8YMGDVJJSYnCwsIkSWvXrtWMGTN0/PjxRqrwXxp8E6q2tlYzZszQlVdeqZ49e0qSXC6X7Ha7wsPDvcZGRUXJ5XJZY34eXk73n+471xi3260ff/zxrPVkZ2crLCzMWvglagDAr6WkpMRali9frtDQUK+2e++994L2c9FFF6lDhw519ldWVvqq5LNyOBwKDAy84PF2u10Oh8MvT4k1OMCkp6dr//79euGFF3xZT4NlZmaqvLzcWo4cOeLvkgAALYTD4bCWsLAw2Ww2r7aLLrrIGltQUKABAwYoODhYgwYN8noYJisrS3369LHWb7vtNl133XVatGiRYmJi1KVLF0nSrl271LdvXwUFBWnAgAH66KOPzltjWVmZRo0apbZt2yo+Pl45OTlnjLHZbNqwYYO1vmPHDvXp08c6zoYNG2Sz2eR0OiX984Ebm82m48eP691339XEiRNVXl4um80mm82mrKys+v2DrIcG3UKaNm2aNm7cqLy8PF1yySVWu8PhUGVlpY4fP+51Faa0tFQOh8Mas2vXLq/9nX5K6edj/u+TS6WlpQoNDVXbtm3PWlNgYGC9UiMAAP7wwAMP6LHHHtPFF1+sO++8U5MmTdL7779f5/itW7cqNDRUubm5kqQTJ07o2muv1e9+9zs9//zzKioq0j333HPe49522206evSo3nnnHbVp00Z33323ysrK6hzvdrs1atQojRw5UuvWrdNXX311zqkcgwYN0vLlyzVv3jwrlP08uPlavQKMx+PR9OnT9corr+jdd99VfHy8V3///v3Vpk0bbd26VWPGjJEkFRYWqri4WElJSZKkpKQkLVq0SGVlZYqMjJQk5ebmKjQ0VN27d7fGvPnmm177zs3NtfaBluPXvN/tK/W5bw6g5Vm0aJGuueYaSdKcOXOUlpamn376qc73obRr105//etfrbfWrlq1SrW1tVq9erWCgoLUo0cPff3117rrrrvqPOann36qv//979q1a5cGDhwoSVq9erW6detW5zbr1q2TzWbTX/7yFwUFBal79+76xz/+oSlTppx1vN1u97r61NjqdQspPT1dzz//vNatW6eQkBC5XC65XC5rXkpYWJgmT56sjIwMvfPOOyooKNDEiROVlJSkK664QpKUnJys7t2769Zbb9XHH3+st956S3PnzlV6erp1BeXOO+/UF198ofvuu0+ffPKJnn76ab344ouaOXOmj08fAIBfV0JCgvU5Ojpaks55JaRXr15er9w/dOiQEhISvALP+f4H/9ChQ2rdurX69+9vtXXt2vWMOas/V1hYeMZxLr/88nMe59dUrwCzcuVKlZeXa8iQIYqOjraW9evXW2Mef/xxXXvttRozZowGDx4sh8Ohl19+2eoPCAjQxo0bFRAQoKSkJN1yyy0aP368Fi5caI2Jj4/XG2+8odzcXPXu3VuPPfaY/vrXvyolJcUHpwwAgP+0adPG+nx68mttbW2d49u1a9foNZmo3reQzicoKEgrVqzQihUr6hwTFxd3xi2i/2vIkCEXNCkJAICWpFu3bvrv//5vr9tOO3fuPOc2Xbt2VXV1tQoKCqxbSIWFhed83LlLly56/vnnVVFRYd0h2b179zmPY7fbf7VfD+c9zQAAGGTs2LGy2WyaMmWKDh48qDfffFOPPvroObfp0qWLRowYoTvuuEMffPCBCgoKdPvtt9f5YMzp49TW1mrq1Kk6dOiQ3nrrLes4dT023alTJ504cUJbt27Vt99+26i/Jk6AAQDAIBdddJFef/117du3T3379tUDDzygRx555LzbPfvss4qJidE111yj0aNHa+rUqdbDNGcTGhqq119/XU6nU3369NEDDzxg/exPXROOBw0apDvvvFM33nijLr74Yi1ZsqRhJ3kBbJ4LuS9kILfbrbCwMJWXlys0NNTf5aCBeAoJaHl++uknFRUVKT4+vsG/VIzGkZOTY73r5VxXb87nXN/xhf79/kU/JQAAAJqvv/3tb7rsssv0b//2b/r44481e/Zs3XDDDb8ovPgKAQYAAJyVy+XSvHnz5HK5FB0dreuvv16LFi3yd1mSCDAAAKAO9913n+677z5/l3FWTOIFAADGIcAAAADjEGAAAE1SM31IFvLNd0uAAQA0Kadftd+YL0GDf53+bn/+swr1xSReAECTEhAQoPDwcOsHDoODg+t88yvM4vF4dOrUKZWVlSk8PFwBAQEN3hcBBgDQ5DgcDknn/pVmmCs8PNz6jhuKAAMAaHJsNpuio6MVGRmpqqoqf5cDH2rTps0vuvJyGgEGANBkBQQE+OSPHZofJvECAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOPUOMHl5eRo1apRiYmJks9m0YcMGr36bzXbWZenSpdaYTp06ndG/ePFir/3s3btXV199tYKCghQbG6slS5Y07AwBAECzU+8Ac/LkSfXu3VsrVqw4a39JSYnXsmbNGtlsNo0ZM8Zr3MKFC73GTZ8+3epzu91KTk5WXFycCgoKtHTpUmVlZWnVqlX1LRcAADRDreu7QWpqqlJTU+vsdzgcXuuvvvqqhg4dqssuu8yrPSQk5Iyxp+Xk5KiyslJr1qyR3W5Xjx495HQ6tWzZMk2dOrW+JQMAgGamUefAlJaW6o033tDkyZPP6Fu8eLE6dOigvn37aunSpaqurrb68vPzNXjwYNntdqstJSVFhYWFOnbs2FmPVVFRIbfb7bUAAIDmqd5XYOrjueeeU0hIiEaPHu3Vfvfdd6tfv36KiIjQjh07lJmZqZKSEi1btkyS5HK5FB8f77VNVFSU1de+ffszjpWdna0FCxY00pkAAICmpFEDzJo1azRu3DgFBQV5tWdkZFifExISZLfbdccddyg7O1uBgYENOlZmZqbXft1ut2JjYxtWOAAAaNIaLcBs375dhYWFWr9+/XnHJiYmqrq6Wl9++aW6dOkih8Oh0tJSrzGn1+uaNxMYGNjg8AMAAMzSaHNgVq9erf79+6t3797nHet0OtWqVStFRkZKkpKSkpSXl6eqqiprTG5urrp06XLW20cAAKBlqXeAOXHihJxOp5xOpySpqKhITqdTxcXF1hi3262XXnpJt99++xnb5+fna/ny5fr444/1xRdfKCcnRzNnztQtt9xihZOxY8fKbrdr8uTJOnDggNavX68nnnjC6xYRAABouep9C+nDDz/U0KFDrfXToWLChAlau3atJOmFF16Qx+PRzTfffMb2gYGBeuGFF5SVlaWKigrFx8dr5syZXuEkLCxMmzdvVnp6uvr376+OHTtq3rx5PEINAAAkSTaPx+PxdxGNwe12KywsTOXl5QoNDfV3OWigTnPe8HcJ9fbl4jR/lwAAxrrQv9/8FhIAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYJzW/i4AABqi05w3/F1CvX25OM3fJQDNRr2vwOTl5WnUqFGKiYmRzWbThg0bvPpvu+022Ww2r2XEiBFeY77//nuNGzdOoaGhCg8P1+TJk3XixAmvMXv37tXVV1+toKAgxcbGasmSJfU/OwAA0CzVO8CcPHlSvXv31ooVK+ocM2LECJWUlFjL//zP/3j1jxs3TgcOHFBubq42btyovLw8TZ061ep3u91KTk5WXFycCgoKtHTpUmVlZWnVqlX1LRcAADRD9b6FlJqaqtTU1HOOCQwMlMPhOGvfoUOHtGnTJu3evVsDBgyQJD355JMaOXKkHn30UcXExCgnJ0eVlZVas2aN7Ha7evToIafTqWXLlnkFHQAA0DI1yiTed999V5GRkerSpYvuuusufffdd1Zffn6+wsPDrfAiScOHD1erVq30wQcfWGMGDx4su91ujUlJSVFhYaGOHTvWGCUDAACD+HwS74gRIzR69GjFx8fr8OHDuv/++5Wamqr8/HwFBATI5XIpMjLSu4jWrRURESGXyyVJcrlcio+P9xoTFRVl9bVv3/6M41ZUVKiiosJad7vdvj41AADQRPg8wNx0003W5169eikhIUGdO3fWu+++q2HDhvn6cJbs7GwtWLCg0fYPAACajkZ/D8xll12mjh076vPPP5ckORwOlZWVeY2prq7W999/b82bcTgcKi0t9Rpzer2uuTWZmZkqLy+3liNHjvj6VAAAQBPR6AHm66+/1nfffafo6GhJUlJSko4fP66CggJrzNtvv63a2lolJiZaY/Ly8lRVVWWNyc3NVZcuXc56+0j658Th0NBQrwUAADRP9Q4wJ06ckNPplNPplCQVFRXJ6XSquLhYJ06c0KxZs7Rz5059+eWX2rp1q/7whz/oN7/5jVJSUiRJ3bp104gRIzRlyhTt2rVL77//vqZNm6abbrpJMTExkqSxY8fKbrdr8uTJOnDggNavX68nnnhCGRkZvjtzAABgrHoHmA8//FB9+/ZV3759JUkZGRnq27ev5s2bp4CAAO3du1e///3v9dvf/laTJ09W//79tX37dgUGBlr7yMnJUdeuXTVs2DCNHDlSV111ldc7XsLCwrR582YVFRWpf//++uMf/6h58+bxCDUAAJDUgEm8Q4YMkcfjqbP/rbfeOu8+IiIitG7dunOOSUhI0Pbt2+tbHgAAaAH4MUcAAGAcAgwAADAOAQYAABiHAAMAAIzj8zfxtgSd5rzh7xLq7cvFaf4uAQAAn+EKDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA49Q7wOTl5WnUqFGKiYmRzWbThg0brL6qqirNnj1bvXr1Urt27RQTE6Px48fr6NGjXvvo1KmTbDab17J48WKvMXv37tXVV1+toKAgxcbGasmSJQ07QwAA0OzUO8CcPHlSvXv31ooVK87oO3XqlPbs2aMHH3xQe/bs0csvv6zCwkL9/ve/P2PswoULVVJSYi3Tp0+3+txut5KTkxUXF6eCggItXbpUWVlZWrVqVX3LBQAAzVDr+m6Qmpqq1NTUs/aFhYUpNzfXq+2pp57S5ZdfruLiYl166aVWe0hIiBwOx1n3k5OTo8rKSq1Zs0Z2u109evSQ0+nUsmXLNHXq1PqWDAAAmplGnwNTXl4um82m8PBwr/bFixerQ4cO6tu3r5YuXarq6mqrLz8/X4MHD5bdbrfaUlJSVFhYqGPHjp31OBUVFXK73V4LAABonup9BaY+fvrpJ82ePVs333yzQkNDrfa7775b/fr1U0REhHbs2KHMzEyVlJRo2bJlkiSXy6X4+HivfUVFRVl97du3P+NY2dnZWrBgQSOeDQAAaCoaLcBUVVXphhtukMfj0cqVK736MjIyrM8JCQmy2+264447lJ2drcDAwAYdLzMz02u/brdbsbGxDSseAAA0aY0SYE6Hl6+++kpvv/2219WXs0lMTFR1dbW+/PJLdenSRQ6HQ6WlpV5jTq/XNW8mMDCwweEHAACYxedzYE6Hl88++0xbtmxRhw4dzruN0+lUq1atFBkZKUlKSkpSXl6eqqqqrDG5ubnq0qXLWW8fAQCAlqXeV2BOnDihzz//3FovKiqS0+lURESEoqOj9Z//+Z/as2ePNm7cqJqaGrlcLklSRESE7Ha78vPz9cEHH2jo0KEKCQlRfn6+Zs6cqVtuucUKJ2PHjtWCBQs0efJkzZ49W/v379cTTzyhxx9/3EenDQAATFbvAPPhhx9q6NCh1vrpeScTJkxQVlaWXnvtNUlSnz59vLZ75513NGTIEAUGBuqFF15QVlaWKioqFB8fr5kzZ3rNXwkLC9PmzZuVnp6u/v37q2PHjpo3bx6PUAMAAEkNCDBDhgyRx+Ops/9cfZLUr18/7dy587zHSUhI0Pbt2+tbHgAAaAH4LSQAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4rf1dAAAALV2nOW/4u4R6+3Jxml+PzxUYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA49Q4weXl5GjVqlGJiYmSz2bRhwwavfo/Ho3nz5ik6Olpt27bV8OHD9dlnn3mN+f777zVu3DiFhoYqPDxckydP1okTJ7zG7N27V1dffbWCgoIUGxurJUuW1P/sAABAs1TvN/GePHlSvXv31qRJkzR69Ogz+pcsWaI///nPeu655xQfH68HH3xQKSkpOnjwoIKCgiRJ48aNU0lJiXJzc1VVVaWJEydq6tSpWrdunSTJ7XYrOTlZw4cP1zPPPKN9+/Zp0qRJCg8P19SpU3/hKQMAmjMT32qL+qt3gElNTVVqaupZ+zwej5YvX665c+fqD3/4gyTpb3/7m6KiorRhwwbddNNNOnTokDZt2qTdu3drwIABkqQnn3xSI0eO1KOPPqqYmBjl5OSosrJSa9askd1uV48ePeR0OrVs2TICDAAA8O0cmKKiIrlcLg0fPtxqCwsLU2JiovLz8yVJ+fn5Cg8Pt8KLJA0fPlytWrXSBx98YI0ZPHiw7Ha7NSYlJUWFhYU6duyYL0sGAAAG8umPObpcLklSVFSUV3tUVJTV53K5FBkZ6V1E69aKiIjwGhMfH3/GPk73tW/f/oxjV1RUqKKiwlp3u92/8GwAAEBT1WyeQsrOzlZYWJi1xMbG+rskAADQSHwaYBwOhySptLTUq720tNTqczgcKisr8+qvrq7W999/7zXmbPv4+TH+r8zMTJWXl1vLkSNHfvkJAQCAJsmnASY+Pl4Oh0Nbt2612txutz744AMlJSVJkpKSknT8+HEVFBRYY95++23V1tYqMTHRGpOXl6eqqiprTG5urrp06XLW20eSFBgYqNDQUK8FAAA0T/UOMCdOnJDT6ZTT6ZT0z4m7TqdTxcXFstlsmjFjhv70pz/ptdde0759+zR+/HjFxMTouuuukyR169ZNI0aM0JQpU7Rr1y69//77mjZtmm666SbFxMRIksaOHSu73a7JkyfrwIEDWr9+vZ544gllZGT47MQBAIC56j2J98MPP9TQoUOt9dOhYsKECVq7dq3uu+8+nTx5UlOnTtXx48d11VVXadOmTdY7YCQpJydH06ZN07Bhw9SqVSuNGTNGf/7zn63+sLAwbd68Wenp6erfv786duyoefPm8Qg1AACQ1IAAM2TIEHk8njr7bTabFi5cqIULF9Y5JiIiwnppXV0SEhK0ffv2+pYHAABaAJ8+Rg3ATLy5FIBpms1j1AAAoOUgwAAAAOMQYAAAgHEIMAAAwDhM4m0hmKQJAGhOuAIDAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHH4MUcA+JWY+KOqXy5O83cJwFlxBQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHJ8HmE6dOslms52xpKenS5KGDBlyRt+dd97ptY/i4mKlpaUpODhYkZGRmjVrlqqrq31dKgAAMFRrX+9w9+7dqqmpsdb379+v3/3ud7r++uuttilTpmjhwoXWenBwsPW5pqZGaWlpcjgc2rFjh0pKSjR+/Hi1adNGDz/8sK/LBQAABvJ5gLn44ou91hcvXqzOnTvrmmuusdqCg4PlcDjOuv3mzZt18OBBbdmyRVFRUerTp48eeughzZ49W1lZWbLb7b4uGQAAGKZR58BUVlbq+eef16RJk2Sz2az2nJwcdezYUT179lRmZqZOnTpl9eXn56tXr16Kioqy2lJSUuR2u3XgwIE6j1VRUSG32+21AACA5snnV2B+bsOGDTp+/Lhuu+02q23s2LGKi4tTTEyM9u7dq9mzZ6uwsFAvv/yyJMnlcnmFF0nWusvlqvNY2dnZWrBgge9PAgAANDmNGmBWr16t1NRUxcTEWG1Tp061Pvfq1UvR0dEaNmyYDh8+rM6dOzf4WJmZmcrIyLDW3W63YmNjG7w/AADQdDVagPnqq6+0ZcsW68pKXRITEyVJn3/+uTp37iyHw6Fdu3Z5jSktLZWkOufNSFJgYKACAwN/YdUAAMAEjTYH5tlnn1VkZKTS0tLOOc7pdEqSoqOjJUlJSUnat2+fysrKrDG5ubkKDQ1V9+7dG6tcAABgkEa5AlNbW6tnn31WEyZMUOvW/zrE4cOHtW7dOo0cOVIdOnTQ3r17NXPmTA0ePFgJCQmSpOTkZHXv3l233nqrlixZIpfLpblz5yo9PZ0rLAAAQFIjBZgtW7aouLhYkyZN8mq32+3asmWLli9frpMnTyo2NlZjxozR3LlzrTEBAQHauHGj7rrrLiUlJaldu3aaMGGC13tjAABAy9YoASY5OVkej+eM9tjYWG3btu2828fFxenNN99sjNIAAEAzwG8hAQAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxGuWnBICWrNOcN/xdAgA0e1yBAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADBOa38XAABoujrNecPfJQBnxRUYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxfB5gsrKyZLPZvJauXbta/T/99JPS09PVoUMHXXTRRRozZoxKS0u99lFcXKy0tDQFBwcrMjJSs2bNUnV1ta9LBQAAhmqUF9n16NFDW7Zs+ddBWv/rMDNnztQbb7yhl156SWFhYZo2bZpGjx6t999/X5JUU1OjtLQ0ORwO7dixQyUlJRo/frzatGmjhx9+uDHKBQAAhmmUANO6dWs5HI4z2svLy7V69WqtW7dO//Ef/yFJevbZZ9WtWzft3LlTV1xxhTZv3qyDBw9qy5YtioqKUp8+ffTQQw9p9uzZysrKkt1ub4ySAQCAQRplDsxnn32mmJgYXXbZZRo3bpyKi4slSQUFBaqqqtLw4cOtsV27dtWll16q/Px8SVJ+fr569eqlqKgoa0xKSorcbrcOHDhQ5zErKirkdru9FgAA0Dz5PMAkJiZq7dq12rRpk1auXKmioiJdffXV+uGHH+RyuWS32xUeHu61TVRUlFwulyTJ5XJ5hZfT/af76pKdna2wsDBriY2N9e2JAQCAJsPnt5BSU1OtzwkJCUpMTFRcXJxefPFFtW3b1teHs2RmZiojI8Nad7vdhBgAAJqpRn+MOjw8XL/97W/1+eefy+FwqLKyUsePH/caU1paas2ZcTgcZzyVdHr9bPNqTgsMDFRoaKjXAgAAmqdGDzAnTpzQ4cOHFR0drf79+6tNmzbaunWr1V9YWKji4mIlJSVJkpKSkrRv3z6VlZVZY3JzcxUaGqru3bs3drkAAMAAPr+FdO+992rUqFGKi4vT0aNHNX/+fAUEBOjmm29WWFiYJk+erIyMDEVERCg0NFTTp09XUlKSrrjiCklScnKyunfvrltvvVVLliyRy+XS3LlzlZ6ersDAQF+XCwAADOTzAPP111/r5ptv1nfffaeLL75YV111lXbu3KmLL75YkvT444+rVatWGjNmjCoqKpSSkqKnn37a2j4gIEAbN27UXXfdpaSkJLVr104TJkzQwoULfV0qAAAwlM3j8Xj8XURjcLvdCgsLU3l5uc/nw3Sa84ZP9wcAgGm+XJzWKPu90L/f/BYSAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABjH5wEmOztbAwcOVEhIiCIjI3XdddepsLDQa8yQIUNks9m8ljvvvNNrTHFxsdLS0hQcHKzIyEjNmjVL1dXVvi4XAAAYqLWvd7ht2zalp6dr4MCBqq6u1v3336/k5GQdPHhQ7dq1s8ZNmTJFCxcutNaDg4OtzzU1NUpLS5PD4dCOHTtUUlKi8ePHq02bNnr44Yd9XTIAADCMzwPMpk2bvNbXrl2ryMhIFRQUaPDgwVZ7cHCwHA7HWfexefNmHTx4UFu2bFFUVJT69Omjhx56SLNnz1ZWVpbsdruvywYAAAZp9Dkw5eXlkqSIiAiv9pycHHXs2FE9e/ZUZmamTp06ZfXl5+erV69eioqKstpSUlLkdrt14MCBsx6noqJCbrfbawEAAM2Tz6/A/Fxtba1mzJihK6+8Uj179rTax44dq7i4OMXExGjv3r2aPXu2CgsL9fLLL0uSXC6XV3iRZK27XK6zHis7O1sLFixopDMBAABNSaMGmPT0dO3fv1/vvfeeV/vUqVOtz7169VJ0dLSGDRumw4cPq3Pnzg06VmZmpjIyMqx1t9ut2NjYhhUOAACatEa7hTRt2jRt3LhR77zzji655JJzjk1MTJQkff7555Ikh8Oh0tJSrzGn1+uaNxMYGKjQ0FCvBQAANE8+DzAej0fTpk3TK6+8orffflvx8fHn3cbpdEqSoqOjJUlJSUnat2+fysrKrDG5ubkKDQ1V9+7dfV0yAAAwjM9vIaWnp2vdunV69dVXFRISYs1ZCQsLU9u2bXX48GGtW7dOI0eOVIcOHbR3717NnDlTgwcPVkJCgiQpOTlZ3bt316233qolS5bI5XJp7ty5Sk9PV2BgoK9LBgAAhvH5FZiVK1eqvLxcQ4YMUXR0tLWsX79ekmS327VlyxYlJyera9eu+uMf/6gxY8bo9ddft/YREBCgjRs3KiAgQElJSbrllls0fvx4r/fGAACAlsvnV2A8Hs85+2NjY7Vt27bz7icuLk5vvvmmr8oCAADNCL+FBAAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACMQ4ABAADGIcAAAADjEGAAAIBxCDAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGIcAAwAAjEOAAQAAxiHAAAAA4xBgAACAcQgwAADAOAQYAABgHAIMAAAwDgEGAAAYhwADAACM06QDzIoVK9SpUycFBQUpMTFRu3bt8ndJAACgCWiyAWb9+vXKyMjQ/PnztWfPHvXu3VspKSkqKyvzd2kAAMDPmmyAWbZsmaZMmaKJEyeqe/fueuaZZxQcHKw1a9b4uzQAAOBnrf1dwNlUVlaqoKBAmZmZVlurVq00fPhw5efnn3WbiooKVVRUWOvl5eWSJLfb7fP6aitO+XyfAACYpDH+vv58vx6P55zjmmSA+fbbb1VTU6OoqCiv9qioKH3yySdn3SY7O1sLFiw4oz02NrZRagQAoCULW964+//hhx8UFhZWZ3+TDDANkZmZqYyMDGu9trZW33//vTp06CCbzeaz47jdbsXGxurIkSMKDQ312X7RcHwnTQvfR9PC99G08H2cn8fj0Q8//KCYmJhzjmuSAaZjx44KCAhQaWmpV3tpaakcDsdZtwkMDFRgYKBXW3h4eGOVqNDQUP7la2L4TpoWvo+mhe+jaeH7OLdzXXk5rUlO4rXb7erfv7+2bt1qtdXW1mrr1q1KSkryY2UAAKApaJJXYCQpIyNDEyZM0IABA3T55Zdr+fLlOnnypCZOnOjv0gAAgJ812QBz44036ptvvtG8efPkcrnUp08fbdq06YyJvb+2wMBAzZ8//4zbVfAfvpOmhe+jaeH7aFr4PnzH5jnfc0oAAABNTJOcAwMAAHAuBBgAAGAcAgwAADAOAQYAABiHAFNPK1asUKdOnRQUFKTExETt2rXL3yW1SNnZ2Ro4cKBCQkIUGRmp6667ToWFhf4uC//f4sWLZbPZNGPGDH+X0qL94x//0C233KIOHTqobdu26tWrlz788EN/l9Ui1dTU6MEHH1R8fLzatm2rzp0766GHHjrv7/2gbgSYeli/fr0yMjI0f/587dmzR71791ZKSorKysr8XVqLs23bNqWnp2vnzp3Kzc1VVVWVkpOTdfLkSX+X1uLt3r1b//Vf/6WEhAR/l9KiHTt2TFdeeaXatGmjv//97zp48KAee+wxtW/f3t+ltUiPPPKIVq5cqaeeekqHDh3SI488oiVLlujJJ5/0d2nG4jHqekhMTNTAgQP11FNPSfrn24FjY2M1ffp0zZkzx8/VtWzffPONIiMjtW3bNg0ePNjf5bRYJ06cUL9+/fT000/rT3/6k/r06aPly5f7u6wWac6cOXr//fe1fft2f5cCSddee62ioqK0evVqq23MmDFq27atnn/+eT9WZi6uwFygyspKFRQUaPjw4VZbq1atNHz4cOXn5/uxMkhSeXm5JCkiIsLPlbRs6enpSktL8/rvBP7x2muvacCAAbr++usVGRmpvn376i9/+Yu/y2qxBg0apK1bt+rTTz+VJH388cd67733lJqa6ufKzNVk38Tb1Hz77beqqak5403AUVFR+uSTT/xUFaR/XgmbMWOGrrzySvXs2dPf5bRYL7zwgvbs2aPdu3f7uxRI+uKLL7Ry5UplZGTo/vvv1+7du3X33XfLbrdrwoQJ/i6vxZkzZ47cbre6du2qgIAA1dTUaNGiRRo3bpy/SzMWAQbGS09P1/79+/Xee+/5u5QW68iRI7rnnnuUm5uroKAgf5cD/TPYDxgwQA8//LAkqW/fvtq/f7+eeeYZAowfvPjii8rJydG6devUo0cPOZ1OzZgxQzExMXwfDUSAuUAdO3ZUQECASktLvdpLS0vlcDj8VBWmTZumjRs3Ki8vT5dccom/y2mxCgoKVFZWpn79+lltNTU1ysvL01NPPaWKigoFBAT4scKWJzo6Wt27d/dq69atm/73f//XTxW1bLNmzdKcOXN00003SZJ69eqlr776StnZ2QSYBmIOzAWy2+3q37+/tm7darXV1tZq69atSkpK8mNlLZPH49G0adP0yiuv6O2331Z8fLy/S2rRhg0bpn379snpdFrLgAEDNG7cODmdTsKLH1x55ZVnvFrg008/VVxcnJ8qatlOnTqlVq28/+QGBASotrbWTxWZjysw9ZCRkaEJEyZowIABuvzyy7V8+XKdPHlSEydO9HdpLU56errWrVunV199VSEhIXK5XJKksLAwtW3b1s/VtTwhISFnzD9q166dOnTowLwkP5k5c6YGDRqkhx9+WDfccIN27dqlVatWadWqVf4urUUaNWqUFi1apEsvvVQ9evTQRx99pGXLlmnSpEn+Ls1cHtTLk08+6bn00ks9drvdc/nll3t27tzp75JaJElnXZ599ll/l4b/75prrvHcc889/i6jRXv99dc9PXv29AQGBnq6du3qWbVqlb9LarHcbrfnnnvu8Vx66aWeoKAgz2WXXeZ54IEHPBUVFf4uzVi8BwYAABiHOTAAAMA4BBgAAGAcAgwAADAOAQYAABiHAAMAAIxDgAEAAMYhwAAAAOMQYAAAgHEIMAAAwDgEGAAAYBwCDAAAMA4BBgAAGOf/AeqVjA6gHxwNAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def examine_labels():\n",
        "    labels = np.int32(np.load(datadir+'data/gas_labels.npy'))\n",
        "    plt.hist(labels[:,0],bins=10,label=\"First digit\")\n",
        "    plt.hist(labels[:,1],bins=10,label=\"Second digit\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.hist(labels[:,2],bins=10,label=\"Third digit\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.hist(labels[:,3],bins=10,label=\"Fourth digit\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.hist(labels[:,4],bins=10,label=\"Fifth digit\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "examine_labels()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bwCSP93T-mOK"
      },
      "source": [
        "## b) Creating a model\n",
        "\n",
        "My initial assumption was that we could just generate the same model we would use for 1 digit for each of the 4 digits that we want to predict (we're predicting 6 on digit 1 always with 100% accuracy, leaving it out of the model for simplicity). \n",
        "\n",
        "![](https://i.imgur.com/y5CGHlz.png)\n",
        "\n",
        "I started the project off by making individual digit predictions and I found that using 2 layers convolution and 2 layers of pooling was an effective model for predicting each of the digits individually. For whole image prediction I just wanted to scale this up and effectively give each digit its own model on all of the original data. This turns our problem into effectively 4 10 category classification problems, which seemed like a more reasonable approach than treating it like a $10^4$ digit classification problem.\n",
        "\n",
        "Additional considerations were reformating the data for digit 2 to be just binary classication and giving it a simpler model. For implementation sake, I left it the same model as the other digits and we still got impressive results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UcucdRBQ-mOL",
        "outputId": "41a737d0-c629-4bca-f9f5-21dd8dca21ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/24\n",
            "44/44 [==============================] - 27s 250ms/step - loss: 6.3362 - d2_loss: 0.4596 - d3_loss: 1.4301 - d4_loss: 2.2896 - d5_loss: 2.1568 - d2_accuracy: 0.7949 - d3_accuracy: 0.5479 - d4_accuracy: 0.1450 - d5_accuracy: 0.2466 - val_loss: 4.6855 - val_d2_loss: 0.1626 - val_d3_loss: 0.4945 - val_d4_loss: 2.2751 - val_d5_loss: 1.7533 - val_d2_accuracy: 0.9454 - val_d3_accuracy: 0.9076 - val_d4_accuracy: 0.1538 - val_d5_accuracy: 0.5575\n",
            "Epoch 2/24\n",
            "44/44 [==============================] - 8s 191ms/step - loss: 3.5964 - d2_loss: 0.0331 - d3_loss: 0.2502 - d4_loss: 2.1944 - d5_loss: 1.1188 - d2_accuracy: 0.9946 - d3_accuracy: 0.9513 - d4_accuracy: 0.2336 - d5_accuracy: 0.7340 - val_loss: 2.6155 - val_d2_loss: 0.0023 - val_d3_loss: 0.0677 - val_d4_loss: 2.0225 - val_d5_loss: 0.5230 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 0.9952 - val_d4_accuracy: 0.2124 - val_d5_accuracy: 0.8786\n",
            "Epoch 3/24\n",
            "44/44 [==============================] - 8s 193ms/step - loss: 1.9222 - d2_loss: 0.0016 - d3_loss: 0.0352 - d4_loss: 1.5808 - d5_loss: 0.3047 - d2_accuracy: 1.0000 - d3_accuracy: 0.9971 - d4_accuracy: 0.5207 - d5_accuracy: 0.9446 - val_loss: 1.2559 - val_d2_loss: 5.7662e-04 - val_d3_loss: 0.0115 - val_d4_loss: 1.1009 - val_d5_loss: 0.1428 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 0.6961 - val_d5_accuracy: 0.9864\n",
            "Epoch 4/24\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.7955 - d2_loss: 5.7967e-04 - d3_loss: 0.0087 - d4_loss: 0.6827 - d5_loss: 0.1036 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.8413 - d5_accuracy: 0.9900 - val_loss: 0.4860 - val_d2_loss: 2.7875e-04 - val_d3_loss: 0.0051 - val_d4_loss: 0.4230 - val_d5_loss: 0.0577 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 0.8388 - val_d5_accuracy: 0.9946\n",
            "Epoch 5/24\n",
            "44/44 [==============================] - 9s 195ms/step - loss: 0.3835 - d2_loss: 3.2511e-04 - d3_loss: 0.0042 - d4_loss: 0.3188 - d5_loss: 0.0601 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9203 - d5_accuracy: 0.9928 - val_loss: 0.1947 - val_d2_loss: 1.4960e-04 - val_d3_loss: 0.0025 - val_d4_loss: 0.1567 - val_d5_loss: 0.0354 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 0.9948 - val_d5_accuracy: 0.9957\n",
            "Epoch 6/24\n",
            "44/44 [==============================] - 9s 196ms/step - loss: 0.2129 - d2_loss: 1.6363e-04 - d3_loss: 0.0028 - d4_loss: 0.1654 - d5_loss: 0.0445 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9699 - d5_accuracy: 0.9947 - val_loss: 0.0894 - val_d2_loss: 7.1826e-05 - val_d3_loss: 0.0017 - val_d4_loss: 0.0649 - val_d5_loss: 0.0228 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9959\n",
            "Epoch 7/24\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.1385 - d2_loss: 8.3211e-05 - d3_loss: 0.0017 - d4_loss: 0.1050 - d5_loss: 0.0317 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9819 - d5_accuracy: 0.9960 - val_loss: 0.0640 - val_d2_loss: 3.6299e-05 - val_d3_loss: 0.0011 - val_d4_loss: 0.0411 - val_d5_loss: 0.0218 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9989\n",
            "Epoch 8/24\n",
            "44/44 [==============================] - 8s 194ms/step - loss: 0.1085 - d2_loss: 5.1625e-05 - d3_loss: 0.0013 - d4_loss: 0.0814 - d5_loss: 0.0258 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9850 - d5_accuracy: 0.9964 - val_loss: 0.0489 - val_d2_loss: 1.9962e-05 - val_d3_loss: 8.3412e-04 - val_d4_loss: 0.0254 - val_d5_loss: 0.0227 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9975\n",
            "Epoch 9/24\n",
            "44/44 [==============================] - 8s 194ms/step - loss: 0.0953 - d2_loss: 2.8770e-05 - d3_loss: 0.0010 - d4_loss: 0.0656 - d5_loss: 0.0286 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9882 - d5_accuracy: 0.9944 - val_loss: 0.0313 - val_d2_loss: 1.2785e-05 - val_d3_loss: 6.6999e-04 - val_d4_loss: 0.0187 - val_d5_loss: 0.0119 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9962\n",
            "Epoch 10/24\n",
            "44/44 [==============================] - 8s 193ms/step - loss: 0.0759 - d2_loss: 2.0606e-05 - d3_loss: 7.4897e-04 - d4_loss: 0.0535 - d5_loss: 0.0216 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9877 - d5_accuracy: 0.9967 - val_loss: 0.0234 - val_d2_loss: 9.0795e-06 - val_d3_loss: 5.1577e-04 - val_d4_loss: 0.0133 - val_d5_loss: 0.0096 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9989\n",
            "Epoch 11/24\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0644 - d2_loss: 1.6964e-05 - d3_loss: 6.2685e-04 - d4_loss: 0.0474 - d5_loss: 0.0163 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9904 - d5_accuracy: 0.9969 - val_loss: 0.0230 - val_d2_loss: 6.4218e-06 - val_d3_loss: 4.2920e-04 - val_d4_loss: 0.0109 - val_d5_loss: 0.0117 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9984\n",
            "Epoch 12/24\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0552 - d2_loss: 1.1725e-05 - d3_loss: 5.2603e-04 - d4_loss: 0.0379 - d5_loss: 0.0168 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9926 - d5_accuracy: 0.9962 - val_loss: 0.0156 - val_d2_loss: 4.8739e-06 - val_d3_loss: 3.4680e-04 - val_d4_loss: 0.0078 - val_d5_loss: 0.0074 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9993\n",
            "Epoch 13/24\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0449 - d2_loss: 8.7586e-06 - d3_loss: 4.1652e-04 - d4_loss: 0.0319 - d5_loss: 0.0126 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9940 - d5_accuracy: 0.9971 - val_loss: 0.0131 - val_d2_loss: 3.7450e-06 - val_d3_loss: 2.9064e-04 - val_d4_loss: 0.0052 - val_d5_loss: 0.0076 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9982\n",
            "Epoch 14/24\n",
            "44/44 [==============================] - 8s 192ms/step - loss: 0.0411 - d2_loss: 7.2285e-06 - d3_loss: 3.9434e-04 - d4_loss: 0.0257 - d5_loss: 0.0150 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9962 - d5_accuracy: 0.9967 - val_loss: 0.0178 - val_d2_loss: 3.0215e-06 - val_d3_loss: 2.9708e-04 - val_d4_loss: 0.0043 - val_d5_loss: 0.0133 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9980\n",
            "Epoch 15/24\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0395 - d2_loss: 5.9718e-06 - d3_loss: 3.1225e-04 - d4_loss: 0.0259 - d5_loss: 0.0133 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9947 - d5_accuracy: 0.9984 - val_loss: 0.0112 - val_d2_loss: 2.5418e-06 - val_d3_loss: 2.1574e-04 - val_d4_loss: 0.0044 - val_d5_loss: 0.0066 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9982\n",
            "Epoch 16/24\n",
            "44/44 [==============================] - 10s 223ms/step - loss: 0.0372 - d2_loss: 4.9604e-06 - d3_loss: 2.9449e-04 - d4_loss: 0.0238 - d5_loss: 0.0130 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9964 - d5_accuracy: 0.9966 - val_loss: 0.0194 - val_d2_loss: 2.1262e-06 - val_d3_loss: 1.9311e-04 - val_d4_loss: 0.0041 - val_d5_loss: 0.0151 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9975\n",
            "Epoch 17/24\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0315 - d2_loss: 4.6416e-06 - d3_loss: 2.6044e-04 - d4_loss: 0.0192 - d5_loss: 0.0121 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9966 - d5_accuracy: 0.9969 - val_loss: 0.0092 - val_d2_loss: 1.7915e-06 - val_d3_loss: 1.7917e-04 - val_d4_loss: 0.0027 - val_d5_loss: 0.0063 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9984\n",
            "Epoch 18/24\n",
            "44/44 [==============================] - 8s 193ms/step - loss: 0.0300 - d2_loss: 4.1487e-06 - d3_loss: 2.1710e-04 - d4_loss: 0.0185 - d5_loss: 0.0113 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9967 - d5_accuracy: 0.9978 - val_loss: 0.0085 - val_d2_loss: 1.5522e-06 - val_d3_loss: 1.4453e-04 - val_d4_loss: 0.0026 - val_d5_loss: 0.0057 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9995\n",
            "Epoch 19/24\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0337 - d2_loss: 3.4879e-06 - d3_loss: 1.9417e-04 - d4_loss: 0.0165 - d5_loss: 0.0171 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9973 - d5_accuracy: 0.9962 - val_loss: 0.0196 - val_d2_loss: 1.3287e-06 - val_d3_loss: 1.3217e-04 - val_d4_loss: 0.0016 - val_d5_loss: 0.0179 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9962\n",
            "Epoch 20/24\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0380 - d2_loss: 2.9635e-06 - d3_loss: 1.7660e-04 - d4_loss: 0.0175 - d5_loss: 0.0203 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9962 - d5_accuracy: 0.9960 - val_loss: 0.0144 - val_d2_loss: 1.1836e-06 - val_d3_loss: 1.1925e-04 - val_d4_loss: 0.0014 - val_d5_loss: 0.0129 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9962\n",
            "Epoch 21/24\n",
            "44/44 [==============================] - 8s 193ms/step - loss: 0.0219 - d2_loss: 2.8172e-06 - d3_loss: 1.5306e-04 - d4_loss: 0.0119 - d5_loss: 0.0098 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9982 - d5_accuracy: 0.9976 - val_loss: 0.0140 - val_d2_loss: 1.0045e-06 - val_d3_loss: 1.0658e-04 - val_d4_loss: 0.0017 - val_d5_loss: 0.0122 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9962\n",
            "Epoch 22/24\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0232 - d2_loss: 2.5765e-06 - d3_loss: 1.5024e-04 - d4_loss: 0.0131 - d5_loss: 0.0099 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9978 - d5_accuracy: 0.9973 - val_loss: 0.0115 - val_d2_loss: 8.7636e-07 - val_d3_loss: 9.6963e-05 - val_d4_loss: 8.8104e-04 - val_d5_loss: 0.0105 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9962\n",
            "Epoch 23/24\n",
            "44/44 [==============================] - 9s 196ms/step - loss: 0.0205 - d2_loss: 2.1182e-06 - d3_loss: 1.3093e-04 - d4_loss: 0.0102 - d5_loss: 0.0101 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9986 - d5_accuracy: 0.9971 - val_loss: 0.0181 - val_d2_loss: 7.7956e-07 - val_d3_loss: 8.5958e-05 - val_d4_loss: 0.0011 - val_d5_loss: 0.0169 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9959\n",
            "Epoch 24/24\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0243 - d2_loss: 2.3797e-06 - d3_loss: 1.2286e-04 - d4_loss: 0.0143 - d5_loss: 0.0098 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9962 - d5_accuracy: 0.9976 - val_loss: 0.0086 - val_d2_loss: 7.3696e-07 - val_d3_loss: 7.9622e-05 - val_d4_loss: 0.0028 - val_d5_loss: 0.0057 - val_d2_accuracy: 1.0000 - val_d3_accuracy: 1.0000 - val_d4_accuracy: 1.0000 - val_d5_accuracy: 0.9980\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6838091be0>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "(x5_train,y5_train), (x5_val,y5_val), (x5_test,y5_test), input5_shape = get_fivedigit_data(shuffle=True)\n",
        "y5_test_t4 = [y5_test[:,i+1,:] for i in range(4)]\n",
        "y5_train_t4 = [y5_train[:,i+1,:] for i in range(4)]\n",
        "\n",
        "class MultiOutputCNNModel():\n",
        "    def digit_model(self,inputs,name):\n",
        "        x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(10, activation=\"softmax\",name=name)(x)\n",
        "        return x\n",
        "    def assemble_full_model(self,input_shape):\n",
        "        inputs = Input(shape=input_shape)\n",
        "        ## Each digit gets its own convoulational model\n",
        "        # d1 = self.digit_model(inputs,\"d1\")\n",
        "        d2 = self.digit_model(inputs,\"d2\")\n",
        "        d3 = self.digit_model(inputs,\"d3\")\n",
        "        d4 = self.digit_model(inputs,\"d4\")\n",
        "        d5 = self.digit_model(inputs,\"d5\")\n",
        "        model = Model(inputs=inputs,outputs=[d2,d3,d4,d5])\n",
        "        return model\n",
        "\n",
        "model = MultiOutputCNNModel().assemble_full_model(input_shape=input5_shape)\n",
        "\n",
        "model.compile(loss = keras.losses.categorical_crossentropy, \n",
        "   optimizer = 'Adam', metrics = ['accuracy'])\n",
        "model.fit(x5_train, y5_train_t4, batch_size = 128, epochs = 24, verbose = 1, \n",
        "          validation_data = (x5_test, y5_test_t4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Btu00R-b-mOM"
      },
      "source": [
        "The per-digit validation accuracy was included in the output above. Obviously accuracy is not the only metric we should be looking at, but it's the one I've chosen to leave in the writeup for demonstration purposes.\n",
        "\n",
        "* Second digit accuracy: 1.0000\n",
        "* Third digit accuracy: 1.0000\n",
        "* Fourth digit accuracy: 1.0000 \n",
        "* Fifth digit accuracy: 0.9980\n",
        "\n",
        "Now we need to examine the prediction accuracy for all five digits at once. We will do so by simply iterating over our test data, predicting using our model, and comparing the digits."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1t7ygA0s-mOM"
      },
      "source": [
        "### Determining 5 digit accuracy\n",
        "\n",
        "The results are below. As expected, we seem to be doing incredibly well except on the last digit which is the most uniform by nature."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DVbPjsGc-mON",
        "outputId": "c3297183-20e8-4696-bffc-9317eedc0da7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have a 5 digit accuracy of 0.9979619565217391\n",
            "The number of times each digit was wrong: [0 0 0 9]\n"
          ]
        }
      ],
      "source": [
        "wrong = np.array([0,0,0,0])\n",
        "all_correct = True\n",
        "ii = 0\n",
        "n = x5_test.shape[0]\n",
        "num_correct = 0\n",
        "\n",
        "for ii in range(n):\n",
        "    ## Generate prediction\n",
        "    data_vec = x5_test[ii].reshape(1,85,195,1)\n",
        "    prediction = model.predict(data_vec,verbose=0)\n",
        "    ## Iterate over all digits predicted\n",
        "    for di in range(4):\n",
        "        predicted_label = np.argmax(prediction[di])\n",
        "        real_label = np.argmax(y5_test_t4[di][ii])\n",
        "        ## If ever wrong, write down which digit and note that\n",
        "        if predicted_label != real_label:\n",
        "            wrong[di] += 1\n",
        "            all_correct = False\n",
        "    ## If we're still right, move on!\n",
        "    if all_correct:\n",
        "        num_correct += 1\n",
        "    all_correct = True\n",
        "print(\"We have a 5 digit accuracy of\",num_correct/n)\n",
        "print(\"The number of times each digit was wrong:\",wrong)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qe2_G4jo-mON"
      },
      "source": [
        "### Experimentation\n",
        "\n",
        "Obviously our goal from here is to improve last digit accuracy. In fact, we can even keep the same model for the first four digits to not increase computational complexity and we can just focus on tweaking our model for the last digit.\n",
        "\n",
        "My first instinct was to throw another fully connected layer at the problem. My initial testing for this project actually involved a third layer that I only removed from this model because I realized I forgot to put it in the diagram.\n",
        "\n",
        "However, upon readding the fully connected layer with RELU activation that was in my original testing the model performed worse. This is because the addition of any kind of fully connected layer will require significantly more epochs to train.\n",
        "\n",
        "I trialed this additional layer many times on different node sizes with different batch sizes. At 64 and 128 nodes it took longer to converge to roughly the same accuracy and at 16 and 32 nodes it was completely unusable (got stuck at 12% training and testing accuracy for most of the epochs).\n",
        "\n",
        "Below I included a demonstration of changing the first layer to have more nodes. We achieve slightly higher accuracy, but this isn't the type of improvement we want to see."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJZLp1gZ-mOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a3214b4-ce7c-4c61-cac4-92e8c92dfc33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "87/87 [==============================] - 7s 51ms/step - loss: 2.2033 - accuracy: 0.2122 - val_loss: 1.8153 - val_accuracy: 0.5057\n",
            "Epoch 2/25\n",
            "87/87 [==============================] - 4s 48ms/step - loss: 0.8979 - accuracy: 0.7916 - val_loss: 0.2571 - val_accuracy: 0.9611\n",
            "Epoch 3/25\n",
            "87/87 [==============================] - 4s 48ms/step - loss: 0.2011 - accuracy: 0.9562 - val_loss: 0.0955 - val_accuracy: 0.9871\n",
            "Epoch 4/25\n",
            "87/87 [==============================] - 4s 42ms/step - loss: 0.1127 - accuracy: 0.9743 - val_loss: 0.0516 - val_accuracy: 0.9921\n",
            "Epoch 5/25\n",
            "87/87 [==============================] - 4s 42ms/step - loss: 0.0734 - accuracy: 0.9822 - val_loss: 0.0360 - val_accuracy: 0.9928\n",
            "Epoch 6/25\n",
            "87/87 [==============================] - 3s 40ms/step - loss: 0.0597 - accuracy: 0.9870 - val_loss: 0.0250 - val_accuracy: 0.9995\n",
            "Epoch 7/25\n",
            "87/87 [==============================] - 4s 41ms/step - loss: 0.0454 - accuracy: 0.9895 - val_loss: 0.0117 - val_accuracy: 0.9993\n",
            "Epoch 8/25\n",
            "87/87 [==============================] - 4s 42ms/step - loss: 0.0342 - accuracy: 0.9931 - val_loss: 0.0117 - val_accuracy: 0.9984\n",
            "Epoch 9/25\n",
            "87/87 [==============================] - 4s 48ms/step - loss: 0.0288 - accuracy: 0.9937 - val_loss: 0.0095 - val_accuracy: 0.9982\n",
            "Epoch 10/25\n",
            "87/87 [==============================] - 4s 48ms/step - loss: 0.0291 - accuracy: 0.9938 - val_loss: 0.0089 - val_accuracy: 0.9984\n",
            "Epoch 11/25\n",
            "87/87 [==============================] - 4s 41ms/step - loss: 0.0263 - accuracy: 0.9937 - val_loss: 0.0063 - val_accuracy: 0.9995\n",
            "Epoch 12/25\n",
            "87/87 [==============================] - 4s 42ms/step - loss: 0.0240 - accuracy: 0.9944 - val_loss: 0.0070 - val_accuracy: 0.9993\n",
            "Epoch 13/25\n",
            "87/87 [==============================] - 4s 48ms/step - loss: 0.0228 - accuracy: 0.9957 - val_loss: 0.0123 - val_accuracy: 0.9962\n",
            "Epoch 14/25\n",
            "87/87 [==============================] - 4s 41ms/step - loss: 0.0190 - accuracy: 0.9949 - val_loss: 0.0054 - val_accuracy: 0.9995\n",
            "Epoch 15/25\n",
            "87/87 [==============================] - 4s 49ms/step - loss: 0.0177 - accuracy: 0.9951 - val_loss: 0.0087 - val_accuracy: 0.9993\n",
            "Epoch 16/25\n",
            "87/87 [==============================] - 5s 62ms/step - loss: 0.0195 - accuracy: 0.9949 - val_loss: 0.0051 - val_accuracy: 0.9995\n",
            "Epoch 17/25\n",
            "87/87 [==============================] - 4s 44ms/step - loss: 0.0171 - accuracy: 0.9960 - val_loss: 0.0064 - val_accuracy: 0.9984\n",
            "Epoch 18/25\n",
            "87/87 [==============================] - 4s 49ms/step - loss: 0.0188 - accuracy: 0.9966 - val_loss: 0.0073 - val_accuracy: 0.9984\n",
            "Epoch 19/25\n",
            "87/87 [==============================] - 4s 50ms/step - loss: 0.0164 - accuracy: 0.9949 - val_loss: 0.0065 - val_accuracy: 0.9989\n",
            "Epoch 20/25\n",
            "87/87 [==============================] - 4s 41ms/step - loss: 0.0143 - accuracy: 0.9957 - val_loss: 0.0066 - val_accuracy: 0.9984\n",
            "Epoch 21/25\n",
            "87/87 [==============================] - 4s 49ms/step - loss: 0.0171 - accuracy: 0.9962 - val_loss: 0.0112 - val_accuracy: 0.9962\n",
            "Epoch 22/25\n",
            "87/87 [==============================] - 4s 49ms/step - loss: 0.0157 - accuracy: 0.9955 - val_loss: 0.0060 - val_accuracy: 0.9975\n",
            "Epoch 23/25\n",
            "87/87 [==============================] - 4s 40ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.0063 - val_accuracy: 0.9980\n",
            "Epoch 24/25\n",
            "87/87 [==============================] - 4s 41ms/step - loss: 0.0177 - accuracy: 0.9962 - val_loss: 0.0046 - val_accuracy: 0.9984\n",
            "Epoch 25/25\n",
            "87/87 [==============================] - 4s 48ms/step - loss: 0.0116 - accuracy: 0.9980 - val_loss: 0.0043 - val_accuracy: 0.9984\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f680dc06c40>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "modelFifth = Sequential() \n",
        "modelFifth.add(Conv2D(64, kernel_size = (3, 3), activation = 'relu', input_shape = input5_shape)) \n",
        "modelFifth.add(MaxPooling2D(pool_size = (2, 2))) \n",
        "modelFifth.add(Conv2D(64, (3, 3), activation = 'relu')) \n",
        "modelFifth.add(MaxPooling2D(pool_size = (2, 2))) \n",
        "modelFifth.add(Flatten()) \n",
        "modelFifth.add(Dropout(0.5)) \n",
        "modelFifth.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "## Compiling and training the model\n",
        "modelFifth.compile(loss = keras.losses.categorical_crossentropy, \n",
        "   optimizer = 'Adam', metrics = ['accuracy'])\n",
        "modelFifth.fit(x5_train, y5_train[:,4,:], batch_size = 64, epochs = 25, verbose = 1, validation_data = (x5_test, y5_test[:,4,:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eMTv7ZX5-mOO"
      },
      "source": [
        "At this point I became interested in exploring other kinds of models outside of convolutional models. It seemed as though we were getting towards the limit of what we could achieve with this kind of model outside of throwing an unbelievable amount of resources.\n",
        "\n",
        "I experimented with a few models. I decided to include the results for my LSTM experimentation below.\n",
        "\n",
        "What I found is that the LSTM model took significantly more epochs to even achieve viability and after 100 epochs we were still reaching about the same results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5mWd66q-mOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d02e7d9d-fde8-4bd3-a163-b90019854892"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "44/44 [==============================] - 4s 51ms/step - loss: 0.3534 - accuracy: 0.1071 - val_loss: 0.3258 - val_accuracy: 0.1166\n",
            "Epoch 2/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.3249 - accuracy: 0.1199 - val_loss: 0.3244 - val_accuracy: 0.1187\n",
            "Epoch 3/100\n",
            "44/44 [==============================] - 1s 34ms/step - loss: 0.3237 - accuracy: 0.1355 - val_loss: 0.3237 - val_accuracy: 0.1377\n",
            "Epoch 4/100\n",
            "44/44 [==============================] - 1s 28ms/step - loss: 0.3231 - accuracy: 0.1334 - val_loss: 0.3203 - val_accuracy: 0.1279\n",
            "Epoch 5/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.3170 - accuracy: 0.1656 - val_loss: 0.3073 - val_accuracy: 0.2464\n",
            "Epoch 6/100\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 0.3096 - accuracy: 0.1801 - val_loss: 0.2863 - val_accuracy: 0.2647\n",
            "Epoch 7/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.3080 - accuracy: 0.2006 - val_loss: 0.2977 - val_accuracy: 0.2600\n",
            "Epoch 8/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.2799 - accuracy: 0.2718 - val_loss: 0.2916 - val_accuracy: 0.1578\n",
            "Epoch 9/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.2675 - accuracy: 0.2894 - val_loss: 0.2479 - val_accuracy: 0.4171\n",
            "Epoch 10/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.2633 - accuracy: 0.2837 - val_loss: 0.2548 - val_accuracy: 0.2935\n",
            "Epoch 11/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.2379 - accuracy: 0.3771 - val_loss: 0.2503 - val_accuracy: 0.3107\n",
            "Epoch 12/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.2258 - accuracy: 0.3872 - val_loss: 0.2197 - val_accuracy: 0.4173\n",
            "Epoch 13/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.3415 - accuracy: 0.1524 - val_loss: 0.3232 - val_accuracy: 0.1214\n",
            "Epoch 14/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.3218 - accuracy: 0.1334 - val_loss: 0.3209 - val_accuracy: 0.1551\n",
            "Epoch 15/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.3200 - accuracy: 0.1614 - val_loss: 0.3179 - val_accuracy: 0.1873\n",
            "Epoch 16/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.3151 - accuracy: 0.1817 - val_loss: 0.3095 - val_accuracy: 0.2074\n",
            "Epoch 17/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.2911 - accuracy: 0.2227 - val_loss: 0.2681 - val_accuracy: 0.3163\n",
            "Epoch 18/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.3174 - accuracy: 0.1674 - val_loss: 0.3030 - val_accuracy: 0.1850\n",
            "Epoch 19/100\n",
            "44/44 [==============================] - 1s 27ms/step - loss: 0.2833 - accuracy: 0.2482 - val_loss: 0.2779 - val_accuracy: 0.2371\n",
            "Epoch 20/100\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.2707 - accuracy: 0.2895 - val_loss: 0.2355 - val_accuracy: 0.4013\n",
            "Epoch 21/100\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.2359 - accuracy: 0.3780 - val_loss: 0.2289 - val_accuracy: 0.4137\n",
            "Epoch 22/100\n",
            "44/44 [==============================] - 1s 30ms/step - loss: 0.2574 - accuracy: 0.3118 - val_loss: 0.2374 - val_accuracy: 0.3610\n",
            "Epoch 23/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.2216 - accuracy: 0.4008 - val_loss: 0.2270 - val_accuracy: 0.3929\n",
            "Epoch 24/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.2196 - accuracy: 0.4055 - val_loss: 0.2334 - val_accuracy: 0.3757\n",
            "Epoch 25/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.2294 - accuracy: 0.3718 - val_loss: 0.2063 - val_accuracy: 0.4563\n",
            "Epoch 26/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.2030 - accuracy: 0.4619 - val_loss: 0.2010 - val_accuracy: 0.4701\n",
            "Epoch 27/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.2289 - accuracy: 0.3724 - val_loss: 0.2111 - val_accuracy: 0.4015\n",
            "Epoch 28/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.2046 - accuracy: 0.4448 - val_loss: 0.2029 - val_accuracy: 0.4341\n",
            "Epoch 29/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1958 - accuracy: 0.4744 - val_loss: 0.2000 - val_accuracy: 0.4527\n",
            "Epoch 30/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.1914 - accuracy: 0.4733 - val_loss: 0.2233 - val_accuracy: 0.3952\n",
            "Epoch 31/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.1978 - accuracy: 0.4548 - val_loss: 0.1918 - val_accuracy: 0.4928\n",
            "Epoch 32/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1833 - accuracy: 0.5149 - val_loss: 0.1797 - val_accuracy: 0.5086\n",
            "Epoch 33/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1815 - accuracy: 0.5034 - val_loss: 0.1806 - val_accuracy: 0.5002\n",
            "Epoch 34/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1788 - accuracy: 0.5182 - val_loss: 0.1716 - val_accuracy: 0.5679\n",
            "Epoch 35/100\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 0.1717 - accuracy: 0.5515 - val_loss: 0.1734 - val_accuracy: 0.5408\n",
            "Epoch 36/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.1718 - accuracy: 0.5439 - val_loss: 0.1818 - val_accuracy: 0.4798\n",
            "Epoch 37/100\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.2156 - accuracy: 0.4169 - val_loss: 0.1897 - val_accuracy: 0.4921\n",
            "Epoch 38/100\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.2116 - accuracy: 0.4405 - val_loss: 0.1876 - val_accuracy: 0.5070\n",
            "Epoch 39/100\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 0.1788 - accuracy: 0.5418 - val_loss: 0.1710 - val_accuracy: 0.5541\n",
            "Epoch 40/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.1578 - accuracy: 0.6298 - val_loss: 0.1523 - val_accuracy: 0.6617\n",
            "Epoch 41/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1495 - accuracy: 0.6472 - val_loss: 0.2191 - val_accuracy: 0.3514\n",
            "Epoch 42/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.1536 - accuracy: 0.6168 - val_loss: 0.1369 - val_accuracy: 0.6920\n",
            "Epoch 43/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.1349 - accuracy: 0.6755 - val_loss: 0.1405 - val_accuracy: 0.6615\n",
            "Epoch 44/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.1241 - accuracy: 0.7221 - val_loss: 0.1982 - val_accuracy: 0.4794\n",
            "Epoch 45/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.1280 - accuracy: 0.7108 - val_loss: 0.1318 - val_accuracy: 0.7070\n",
            "Epoch 46/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1196 - accuracy: 0.7157 - val_loss: 0.1252 - val_accuracy: 0.6929\n",
            "Epoch 47/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1078 - accuracy: 0.7567 - val_loss: 0.1182 - val_accuracy: 0.7031\n",
            "Epoch 48/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1096 - accuracy: 0.7465 - val_loss: 0.1148 - val_accuracy: 0.7398\n",
            "Epoch 49/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1016 - accuracy: 0.7652 - val_loss: 0.1204 - val_accuracy: 0.6957\n",
            "Epoch 50/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0902 - accuracy: 0.8088 - val_loss: 0.0971 - val_accuracy: 0.7686\n",
            "Epoch 51/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1076 - accuracy: 0.7351 - val_loss: 0.1218 - val_accuracy: 0.6626\n",
            "Epoch 52/100\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 0.0867 - accuracy: 0.8145 - val_loss: 0.0858 - val_accuracy: 0.8385\n",
            "Epoch 53/100\n",
            "44/44 [==============================] - 1s 29ms/step - loss: 0.1141 - accuracy: 0.7434 - val_loss: 0.1155 - val_accuracy: 0.7149\n",
            "Epoch 54/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.1027 - accuracy: 0.7735 - val_loss: 0.0961 - val_accuracy: 0.7810\n",
            "Epoch 55/100\n",
            "44/44 [==============================] - 1s 20ms/step - loss: 0.0682 - accuracy: 0.8675 - val_loss: 0.0896 - val_accuracy: 0.7856\n",
            "Epoch 56/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0608 - accuracy: 0.8842 - val_loss: 0.0538 - val_accuracy: 0.9040\n",
            "Epoch 57/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0515 - accuracy: 0.9020 - val_loss: 0.2781 - val_accuracy: 0.4835\n",
            "Epoch 58/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.1097 - accuracy: 0.7835 - val_loss: 0.0547 - val_accuracy: 0.9085\n",
            "Epoch 59/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.0495 - accuracy: 0.9103 - val_loss: 0.0477 - val_accuracy: 0.9164\n",
            "Epoch 60/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.0500 - accuracy: 0.9065 - val_loss: 0.0491 - val_accuracy: 0.9155\n",
            "Epoch 61/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0999 - accuracy: 0.7909 - val_loss: 0.0842 - val_accuracy: 0.8263\n",
            "Epoch 62/100\n",
            "44/44 [==============================] - 1s 20ms/step - loss: 0.0583 - accuracy: 0.8880 - val_loss: 0.0468 - val_accuracy: 0.9198\n",
            "Epoch 63/100\n",
            "44/44 [==============================] - 1s 21ms/step - loss: 0.0411 - accuracy: 0.9306 - val_loss: 0.0402 - val_accuracy: 0.9416\n",
            "Epoch 64/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.0391 - accuracy: 0.9388 - val_loss: 0.0375 - val_accuracy: 0.9488\n",
            "Epoch 65/100\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.0374 - accuracy: 0.9467 - val_loss: 0.0378 - val_accuracy: 0.9558\n",
            "Epoch 66/100\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.0385 - accuracy: 0.9395 - val_loss: 0.0375 - val_accuracy: 0.9457\n",
            "Epoch 67/100\n",
            "44/44 [==============================] - 1s 25ms/step - loss: 0.0334 - accuracy: 0.9523 - val_loss: 0.0310 - val_accuracy: 0.9638\n",
            "Epoch 68/100\n",
            "44/44 [==============================] - 1s 24ms/step - loss: 0.0307 - accuracy: 0.9601 - val_loss: 0.0308 - val_accuracy: 0.9626\n",
            "Epoch 69/100\n",
            "44/44 [==============================] - 1s 31ms/step - loss: 0.0269 - accuracy: 0.9703 - val_loss: 0.0427 - val_accuracy: 0.9201\n",
            "Epoch 70/100\n",
            "44/44 [==============================] - 1s 20ms/step - loss: 0.0612 - accuracy: 0.8922 - val_loss: 0.0334 - val_accuracy: 0.9678\n",
            "Epoch 71/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0272 - accuracy: 0.9732 - val_loss: 0.0307 - val_accuracy: 0.9563\n",
            "Epoch 72/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0256 - accuracy: 0.9681 - val_loss: 0.0267 - val_accuracy: 0.9647\n",
            "Epoch 73/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0236 - accuracy: 0.9719 - val_loss: 0.0771 - val_accuracy: 0.8311\n",
            "Epoch 74/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0625 - accuracy: 0.8909 - val_loss: 0.0274 - val_accuracy: 0.9767\n",
            "Epoch 75/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0225 - accuracy: 0.9779 - val_loss: 0.0207 - val_accuracy: 0.9794\n",
            "Epoch 76/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0230 - accuracy: 0.9726 - val_loss: 0.0223 - val_accuracy: 0.9740\n",
            "Epoch 77/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0196 - accuracy: 0.9750 - val_loss: 0.0188 - val_accuracy: 0.9794\n",
            "Epoch 78/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0180 - accuracy: 0.9770 - val_loss: 0.0270 - val_accuracy: 0.9599\n",
            "Epoch 79/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.0182 - accuracy: 0.9761 - val_loss: 0.0230 - val_accuracy: 0.9665\n",
            "Epoch 80/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.1233 - accuracy: 0.7887 - val_loss: 0.2039 - val_accuracy: 0.6327\n",
            "Epoch 81/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.0671 - accuracy: 0.9063 - val_loss: 0.0354 - val_accuracy: 0.9785\n",
            "Epoch 82/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0313 - accuracy: 0.9790 - val_loss: 0.0284 - val_accuracy: 0.9801\n",
            "Epoch 83/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.0270 - accuracy: 0.9777 - val_loss: 0.0291 - val_accuracy: 0.9697\n",
            "Epoch 84/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.0236 - accuracy: 0.9772 - val_loss: 0.0228 - val_accuracy: 0.9798\n",
            "Epoch 85/100\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.0208 - accuracy: 0.9772 - val_loss: 0.0177 - val_accuracy: 0.9819\n",
            "Epoch 86/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.0168 - accuracy: 0.9801 - val_loss: 0.0164 - val_accuracy: 0.9812\n",
            "Epoch 87/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0227 - accuracy: 0.9663 - val_loss: 0.0199 - val_accuracy: 0.9826\n",
            "Epoch 88/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0168 - accuracy: 0.9783 - val_loss: 0.0123 - val_accuracy: 0.9905\n",
            "Epoch 89/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0124 - accuracy: 0.9859 - val_loss: 0.0115 - val_accuracy: 0.9912\n",
            "Epoch 90/100\n",
            "44/44 [==============================] - 1s 17ms/step - loss: 0.0105 - accuracy: 0.9904 - val_loss: 0.0099 - val_accuracy: 0.9923\n",
            "Epoch 91/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0092 - accuracy: 0.9922 - val_loss: 0.0102 - val_accuracy: 0.9921\n",
            "Epoch 92/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0089 - accuracy: 0.9913 - val_loss: 0.0162 - val_accuracy: 0.9751\n",
            "Epoch 93/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0415 - accuracy: 0.9337 - val_loss: 0.0186 - val_accuracy: 0.9708\n",
            "Epoch 94/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0150 - accuracy: 0.9815 - val_loss: 0.0507 - val_accuracy: 0.8965\n",
            "Epoch 95/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0955 - accuracy: 0.8556 - val_loss: 0.0169 - val_accuracy: 0.9909\n",
            "Epoch 96/100\n",
            "44/44 [==============================] - 1s 19ms/step - loss: 0.0126 - accuracy: 0.9900 - val_loss: 0.0097 - val_accuracy: 0.9912\n",
            "Epoch 97/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0090 - accuracy: 0.9920 - val_loss: 0.0095 - val_accuracy: 0.9943\n",
            "Epoch 98/100\n",
            "44/44 [==============================] - 1s 18ms/step - loss: 0.0072 - accuracy: 0.9940 - val_loss: 0.0070 - val_accuracy: 0.9943\n",
            "Epoch 99/100\n",
            "44/44 [==============================] - 1s 23ms/step - loss: 0.0067 - accuracy: 0.9940 - val_loss: 0.0076 - val_accuracy: 0.9930\n",
            "Epoch 100/100\n",
            "44/44 [==============================] - 1s 22ms/step - loss: 0.0061 - accuracy: 0.9944 - val_loss: 0.0063 - val_accuracy: 0.9946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as lstm_cell_5_layer_call_fn, lstm_cell_5_layer_call_and_return_conditional_losses while saving (showing 2 of 2). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "x5_train_t = x5_train.reshape(-1,85,195)\n",
        "x5_test_t = x5_test.reshape(-1,85,195)\n",
        "from keras.layers import SimpleRNN, TimeDistributed, LSTM \n",
        "\n",
        "modelFifthLSTM = Sequential()\n",
        "modelFifthLSTM.add(LSTM(128,input_shape=x5_train_t.shape[1:]))\n",
        "modelFifthLSTM.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "modelFifthLSTM.compile(loss = keras.losses.binary_crossentropy, \n",
        "   optimizer = keras.optimizers.Adam(), metrics = ['accuracy'])\n",
        "modelFifthLSTM.fit(x5_train_t, y5_train[:,4,:], batch_size = 128, epochs = 100, verbose = 1, validation_data = (x5_test_t, y5_test[:,4,:]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "My next approach would've been to use less input data in predicting the last digit. We know the first half of the image doesn't give much additional context as to what the last digit is going to be, especially since the last digit is so uniform. We touch on this approach in part b of the project."
      ],
      "metadata": {
        "id": "hga8W1zPnasl"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLyD8Ona-mOP"
      },
      "source": [
        "## c) Training the model without splitting\n",
        "\n",
        "As part of this project, we were interested in observing what would happen if we didn't shuffle the data before training on it. Since this data is sequential in nature (gas usage on the meter strictly increases over time), my hypothesis was that we would be overfitting on the first few digits to smaller values in our validation and testing predictions and that the model would be impractical."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gh02cu_P-mOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3daf69bf-7f62-4d11-867f-c26a7d8b3d7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "44/44 [==============================] - 15s 246ms/step - loss: 6.0910 - d2_loss: 0.0713 - d3_loss: 1.4888 - d4_loss: 2.2594 - d5_loss: 2.2715 - d2_accuracy: 0.9788 - d3_accuracy: 0.4573 - d4_accuracy: 0.1395 - d5_accuracy: 0.1511 - val_loss: 78.2790 - val_d2_loss: 59.0557 - val_d3_loss: 14.7048 - val_d4_loss: 2.1970 - val_d5_loss: 2.3215 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0000e+00 - val_d4_accuracy: 0.3641 - val_d5_accuracy: 0.1442\n",
            "Epoch 2/25\n",
            "44/44 [==============================] - 8s 188ms/step - loss: 3.6149 - d2_loss: 0.0000e+00 - d3_loss: 0.4122 - d4_loss: 1.4643 - d5_loss: 1.7384 - d2_accuracy: 1.0000 - d3_accuracy: 0.8906 - d4_accuracy: 0.6632 - d5_accuracy: 0.5289 - val_loss: 88.4694 - val_d2_loss: 60.6339 - val_d3_loss: 24.1948 - val_d4_loss: 1.7146 - val_d5_loss: 1.9261 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0016 - val_d4_accuracy: 0.5573 - val_d5_accuracy: 0.4155\n",
            "Epoch 3/25\n",
            "44/44 [==============================] - 8s 189ms/step - loss: 0.9857 - d2_loss: 0.0000e+00 - d3_loss: 0.0772 - d4_loss: 0.2943 - d5_loss: 0.6142 - d2_accuracy: 1.0000 - d3_accuracy: 0.9915 - d4_accuracy: 0.9494 - d5_accuracy: 0.8659 - val_loss: 94.5951 - val_d2_loss: 60.6548 - val_d3_loss: 31.5076 - val_d4_loss: 1.2747 - val_d5_loss: 1.1580 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0224 - val_d4_accuracy: 0.7808 - val_d5_accuracy: 0.6850\n",
            "Epoch 4/25\n",
            "44/44 [==============================] - 8s 191ms/step - loss: 0.3512 - d2_loss: 0.0000e+00 - d3_loss: 0.0225 - d4_loss: 0.0798 - d5_loss: 0.2488 - d2_accuracy: 1.0000 - d3_accuracy: 0.9986 - d4_accuracy: 0.9879 - d5_accuracy: 0.9446 - val_loss: 98.4334 - val_d2_loss: 60.6550 - val_d3_loss: 35.4899 - val_d4_loss: 1.4433 - val_d5_loss: 0.8452 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0186 - val_d4_accuracy: 0.8397 - val_d5_accuracy: 0.7455\n",
            "Epoch 5/25\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.1898 - d2_loss: 0.0000e+00 - d3_loss: 0.0084 - d4_loss: 0.0434 - d5_loss: 0.1379 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9909 - d5_accuracy: 0.9719 - val_loss: 102.0251 - val_d2_loss: 60.6550 - val_d3_loss: 39.1575 - val_d4_loss: 1.5246 - val_d5_loss: 0.6880 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0177 - val_d4_accuracy: 0.8010 - val_d5_accuracy: 0.7887\n",
            "Epoch 6/25\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.1237 - d2_loss: 0.0000e+00 - d3_loss: 0.0047 - d4_loss: 0.0238 - d5_loss: 0.0952 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9967 - d5_accuracy: 0.9822 - val_loss: 104.1883 - val_d2_loss: 60.6550 - val_d3_loss: 41.4473 - val_d4_loss: 1.6534 - val_d5_loss: 0.4326 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0195 - val_d4_accuracy: 0.8193 - val_d5_accuracy: 0.8628\n",
            "Epoch 7/25\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0874 - d2_loss: 0.0000e+00 - d3_loss: 0.0031 - d4_loss: 0.0138 - d5_loss: 0.0704 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9995 - d5_accuracy: 0.9866 - val_loss: 106.1495 - val_d2_loss: 60.6550 - val_d3_loss: 43.4414 - val_d4_loss: 1.5580 - val_d5_loss: 0.4951 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0211 - val_d4_accuracy: 0.8596 - val_d5_accuracy: 0.8782\n",
            "Epoch 8/25\n",
            "44/44 [==============================] - 8s 190ms/step - loss: 0.0676 - d2_loss: 0.0000e+00 - d3_loss: 0.0019 - d4_loss: 0.0105 - d5_loss: 0.0552 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9995 - d5_accuracy: 0.9886 - val_loss: 107.6981 - val_d2_loss: 60.6550 - val_d3_loss: 44.9646 - val_d4_loss: 1.6277 - val_d5_loss: 0.4509 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0220 - val_d4_accuracy: 0.8399 - val_d5_accuracy: 0.8750\n",
            "Epoch 9/25\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0573 - d2_loss: 0.0000e+00 - d3_loss: 0.0016 - d4_loss: 0.0070 - d5_loss: 0.0488 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9998 - d5_accuracy: 0.9904 - val_loss: 109.3572 - val_d2_loss: 60.6550 - val_d3_loss: 46.3735 - val_d4_loss: 1.7847 - val_d5_loss: 0.5440 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0206 - val_d4_accuracy: 0.8388 - val_d5_accuracy: 0.8467\n",
            "Epoch 10/25\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0460 - d2_loss: 0.0000e+00 - d3_loss: 0.0011 - d4_loss: 0.0061 - d5_loss: 0.0387 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9998 - d5_accuracy: 0.9924 - val_loss: 110.6838 - val_d2_loss: 60.6550 - val_d3_loss: 47.3895 - val_d4_loss: 1.7059 - val_d5_loss: 0.9334 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0226 - val_d4_accuracy: 0.8250 - val_d5_accuracy: 0.7538\n",
            "Epoch 11/25\n",
            "44/44 [==============================] - 8s 192ms/step - loss: 0.0576 - d2_loss: 0.0000e+00 - d3_loss: 0.0010 - d4_loss: 0.0045 - d5_loss: 0.0520 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9998 - d5_accuracy: 0.9851 - val_loss: 110.9819 - val_d2_loss: 60.6550 - val_d3_loss: 48.1558 - val_d4_loss: 1.7256 - val_d5_loss: 0.4456 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0392 - val_d4_accuracy: 0.8295 - val_d5_accuracy: 0.8750\n",
            "Epoch 12/25\n",
            "44/44 [==============================] - 8s 191ms/step - loss: 0.0377 - d2_loss: 0.0000e+00 - d3_loss: 6.4689e-04 - d4_loss: 0.0032 - d5_loss: 0.0339 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9929 - val_loss: 112.2859 - val_d2_loss: 60.6550 - val_d3_loss: 49.4196 - val_d4_loss: 1.7689 - val_d5_loss: 0.4425 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0394 - val_d4_accuracy: 0.8410 - val_d5_accuracy: 0.8562\n",
            "Epoch 13/25\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0277 - d2_loss: 0.0000e+00 - d3_loss: 5.1186e-04 - d4_loss: 0.0027 - d5_loss: 0.0245 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9955 - val_loss: 113.3944 - val_d2_loss: 60.6550 - val_d3_loss: 50.6422 - val_d4_loss: 1.8535 - val_d5_loss: 0.2437 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0387 - val_d4_accuracy: 0.8299 - val_d5_accuracy: 0.9337\n",
            "Epoch 14/25\n",
            "44/44 [==============================] - 10s 219ms/step - loss: 0.0341 - d2_loss: 0.0000e+00 - d3_loss: 3.8101e-04 - d4_loss: 0.0023 - d5_loss: 0.0314 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9933 - val_loss: 113.6182 - val_d2_loss: 60.6550 - val_d3_loss: 50.8141 - val_d4_loss: 1.8220 - val_d5_loss: 0.3271 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0417 - val_d4_accuracy: 0.8295 - val_d5_accuracy: 0.9051\n",
            "Epoch 15/25\n",
            "44/44 [==============================] - 8s 192ms/step - loss: 0.0267 - d2_loss: 0.0000e+00 - d3_loss: 2.3195e-04 - d4_loss: 0.0014 - d5_loss: 0.0251 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9958 - val_loss: 114.4003 - val_d2_loss: 60.6550 - val_d3_loss: 51.4863 - val_d4_loss: 1.8606 - val_d5_loss: 0.3984 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0451 - val_d4_accuracy: 0.8442 - val_d5_accuracy: 0.8990\n",
            "Epoch 16/25\n",
            "44/44 [==============================] - 10s 224ms/step - loss: 0.0248 - d2_loss: 0.0000e+00 - d3_loss: 1.7850e-04 - d4_loss: 0.0018 - d5_loss: 0.0228 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9998 - d5_accuracy: 0.9953 - val_loss: 114.8347 - val_d2_loss: 60.6550 - val_d3_loss: 51.8291 - val_d4_loss: 1.8696 - val_d5_loss: 0.4810 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0455 - val_d4_accuracy: 0.8732 - val_d5_accuracy: 0.8680\n",
            "Epoch 17/25\n",
            "44/44 [==============================] - 10s 220ms/step - loss: 0.0243 - d2_loss: 0.0000e+00 - d3_loss: 1.5763e-04 - d4_loss: 0.0012 - d5_loss: 0.0230 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9937 - val_loss: 115.1247 - val_d2_loss: 60.6550 - val_d3_loss: 52.1904 - val_d4_loss: 1.9053 - val_d5_loss: 0.3740 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0455 - val_d4_accuracy: 0.8544 - val_d5_accuracy: 0.8947\n",
            "Epoch 18/25\n",
            "44/44 [==============================] - 8s 192ms/step - loss: 0.0206 - d2_loss: 0.0000e+00 - d3_loss: 1.3084e-04 - d4_loss: 0.0024 - d5_loss: 0.0180 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9996 - d5_accuracy: 0.9967 - val_loss: 115.4010 - val_d2_loss: 60.6550 - val_d3_loss: 52.6379 - val_d4_loss: 1.8708 - val_d5_loss: 0.2372 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0453 - val_d4_accuracy: 0.8589 - val_d5_accuracy: 0.9185\n",
            "Epoch 19/25\n",
            "44/44 [==============================] - 9s 194ms/step - loss: 0.0226 - d2_loss: 0.0000e+00 - d3_loss: 1.0329e-04 - d4_loss: 0.0043 - d5_loss: 0.0181 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9989 - d5_accuracy: 0.9966 - val_loss: 115.7228 - val_d2_loss: 60.6550 - val_d3_loss: 52.8548 - val_d4_loss: 1.9263 - val_d5_loss: 0.2866 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0485 - val_d4_accuracy: 0.8465 - val_d5_accuracy: 0.9269\n",
            "Epoch 20/25\n",
            "44/44 [==============================] - 8s 192ms/step - loss: 0.0202 - d2_loss: 0.0000e+00 - d3_loss: 1.5488e-04 - d4_loss: 0.0017 - d5_loss: 0.0184 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 0.9996 - d5_accuracy: 0.9949 - val_loss: 116.2830 - val_d2_loss: 60.6550 - val_d3_loss: 53.2456 - val_d4_loss: 2.0563 - val_d5_loss: 0.3261 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0464 - val_d4_accuracy: 0.8410 - val_d5_accuracy: 0.9053\n",
            "Epoch 21/25\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0211 - d2_loss: 0.0000e+00 - d3_loss: 7.7035e-05 - d4_loss: 0.0011 - d5_loss: 0.0199 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9951 - val_loss: 116.2384 - val_d2_loss: 60.6550 - val_d3_loss: 53.4455 - val_d4_loss: 1.8714 - val_d5_loss: 0.2665 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0600 - val_d4_accuracy: 0.8567 - val_d5_accuracy: 0.9167\n",
            "Epoch 22/25\n",
            "44/44 [==============================] - 9s 194ms/step - loss: 0.0186 - d2_loss: 0.0000e+00 - d3_loss: 5.7914e-05 - d4_loss: 7.8525e-04 - d5_loss: 0.0178 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9957 - val_loss: 116.5928 - val_d2_loss: 60.6550 - val_d3_loss: 53.6504 - val_d4_loss: 1.9858 - val_d5_loss: 0.3017 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0707 - val_d4_accuracy: 0.8431 - val_d5_accuracy: 0.9395\n",
            "Epoch 23/25\n",
            "44/44 [==============================] - 10s 221ms/step - loss: 0.0255 - d2_loss: 0.0000e+00 - d3_loss: 4.4019e-05 - d4_loss: 5.5300e-04 - d5_loss: 0.0249 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9942 - val_loss: 117.0580 - val_d2_loss: 60.6550 - val_d3_loss: 53.9543 - val_d4_loss: 2.1136 - val_d5_loss: 0.3352 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0466 - val_d4_accuracy: 0.8349 - val_d5_accuracy: 0.9121\n",
            "Epoch 24/25\n",
            "44/44 [==============================] - 10s 222ms/step - loss: 0.0157 - d2_loss: 0.0000e+00 - d3_loss: 4.0230e-05 - d4_loss: 4.1699e-04 - d5_loss: 0.0152 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9973 - val_loss: 116.9437 - val_d2_loss: 60.6550 - val_d3_loss: 54.0450 - val_d4_loss: 1.8910 - val_d5_loss: 0.3527 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0627 - val_d4_accuracy: 0.8582 - val_d5_accuracy: 0.9201\n",
            "Epoch 25/25\n",
            "44/44 [==============================] - 9s 194ms/step - loss: 0.0197 - d2_loss: 0.0000e+00 - d3_loss: 5.6382e-05 - d4_loss: 4.3812e-04 - d5_loss: 0.0192 - d2_accuracy: 1.0000 - d3_accuracy: 1.0000 - d4_accuracy: 1.0000 - d5_accuracy: 0.9949 - val_loss: 116.9703 - val_d2_loss: 60.6550 - val_d3_loss: 54.2646 - val_d4_loss: 1.7982 - val_d5_loss: 0.2525 - val_d2_accuracy: 0.0512 - val_d3_accuracy: 0.0620 - val_d4_accuracy: 0.8757 - val_d5_accuracy: 0.9287\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f684d017100>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "(x5_train,y5_train), (x5_val,y5_val), (x5_test,y5_test), input5_shape = get_fivedigit_data(shuffle=False)\n",
        "y5_test_t4 = [y5_test[:,i+1,:] for i in range(4)]\n",
        "y5_train_t4 = [y5_train[:,i+1,:] for i in range(4)]\n",
        "\n",
        "class MultiOutputCNNModel():\n",
        "    def digit_model(self,inputs,name):\n",
        "        x = Conv2D(32, kernel_size=(3, 3), activation=\"relu\")(inputs)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        x = Conv2D(64, kernel_size=(3, 3), activation=\"relu\")(x)\n",
        "        x = MaxPooling2D(pool_size=(2, 2))(x)\n",
        "        x = Flatten()(x)\n",
        "        x = Dropout(0.5)(x)\n",
        "        x = Dense(10, activation=\"softmax\",name=name)(x)\n",
        "        return x\n",
        "    def assemble_full_model(self,input_shape):\n",
        "        inputs = Input(shape=input_shape)\n",
        "        ## Each digit gets its own convoulational model\n",
        "        # d1 = self.digit_model(inputs,\"d1\")\n",
        "        d2 = self.digit_model(inputs,\"d2\")\n",
        "        d3 = self.digit_model(inputs,\"d3\")\n",
        "        d4 = self.digit_model(inputs,\"d4\")\n",
        "        d5 = self.digit_model(inputs,\"d5\")\n",
        "        model = Model(inputs=inputs,outputs=[d2,d3,d4,d5])\n",
        "        return model\n",
        "\n",
        "modelun = MultiOutputCNNModel().assemble_full_model(input_shape=input5_shape)\n",
        "\n",
        "modelun.compile(loss = keras.losses.categorical_crossentropy, \n",
        "   optimizer = 'Adam', metrics = ['accuracy'])\n",
        "modelun.fit(x5_train, y5_train_t4, batch_size = 128, epochs = 25, verbose = 1, \n",
        "          validation_data = (x5_test, y5_test_t4))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjyKs3rd-mOP"
      },
      "source": [
        "The final validation accuracies were:\n",
        "* Digit 2: 0.0512\n",
        "* Digit 3: 0.0620\n",
        "* Digit 4: 0.8757\n",
        "* Digit 5: 0.9297\n",
        "\n",
        "Clearly our model REALLY struggled with the unshuffled data, specifically on the second and third digits of the testing data. However these results align with our hypothesis. Our training data is on the first half of the data where most of the data has a second digit of 1. Then the testing data will mostly have a 2 for the second digit as we can tell by the histogram. Obviously our model will overfit to the training data - it doesn't know any better. Digit 3 seems to share a similar fate.\n",
        "\n",
        "We do better on digits 4 and 5 because these are the ones that changed more often so their distribution was more uniform. Therefore our training set is still somewhat representative of the testing set. Our results are probably comparable to shuffling the data but using a smaller sample size for training.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GJPGG5r-mOQ"
      },
      "source": [
        "### Calculating all five digits accuracy\n",
        "\n",
        "This is going to be terrible and it's realistically not even worth doing but just for completion sake."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzsc7BuM-mOQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1eb7cec-d31d-42dd-9756-7d15942f3eb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have a 5 digit accuracy of 0.0\n",
            "The number of times each digit was wrong: [4190 4142  549  315]\n"
          ]
        }
      ],
      "source": [
        "wrong = np.array([0,0,0,0])\n",
        "all_correct = True\n",
        "ii = 0\n",
        "n = x5_test.shape[0]\n",
        "num_correct = 0\n",
        "\n",
        "for ii in range(n):\n",
        "    ## Generate prediction\n",
        "    data_vec = x5_test[ii].reshape(1,85,195,1)\n",
        "    prediction = modelun.predict(data_vec,verbose=0)\n",
        "    ## Iterate over all digits predicted\n",
        "    for di in range(4):\n",
        "        predicted_label = np.argmax(prediction[di])\n",
        "        real_label = np.argmax(y5_test_t4[di][ii])\n",
        "        ## If ever wrong, write down which digit and note that\n",
        "        if predicted_label != real_label:\n",
        "            wrong[di] += 1\n",
        "            all_correct = False\n",
        "    ## If we're still right, move on!\n",
        "    if all_correct:\n",
        "        num_correct += 1\n",
        "    all_correct = True\n",
        "print(\"We have a 5 digit accuracy of\",num_correct/n)\n",
        "print(\"The number of times each digit was wrong:\",wrong)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR64sp_7-mOQ"
      },
      "source": [
        "I thought we would get at least one prediction correct. However that would require getting the second and the third digit correct, and based off our individual accuracies even if those were independent we would only expect that to happen 0.3% of the time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYqZi0CG-mOR"
      },
      "source": [
        "# Problem 2: Single Digit Predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sd2G66UW-mOR"
      },
      "source": [
        "## Problem 2a: Classify the isolated digits\n",
        "\n",
        "This is where I started with this project.\n",
        "\n",
        "In this section, we will be using a dataset of all of the digits found in these readings isolated into 85x45 images. Effectively this turns into an MNIST type of problem but in a real world context.\n",
        "\n",
        "I actually started off by testing this exact model on MNIST first and got 99.2% test accuracy, but I've left those results out of this notebook. That can be left as an exercise for the reader."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qehhWKXC-mOR"
      },
      "source": [
        "### Data preprocessing\n",
        "\n",
        "This code is largely the same as before but we are now dealing with more images of smaller size."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVDYMVaO-mOR"
      },
      "outputs": [],
      "source": [
        "## Retrieving the isolated digits\n",
        "def get_iso_digits_helper(shuffle):\n",
        "    data=np.float64(np.load(datadir+'data/iso_data.npy'))\n",
        "    labels=np.float32(np.load(datadir+'data/iso_labels.npy'))\n",
        "    data=np.float32(data)/255.\n",
        "    n = data.shape[0]\n",
        "    ## Shuffling data\n",
        "    if shuffle:\n",
        "        order = np.random.permutation(n)\n",
        "        data = data[order]\n",
        "        labels = labels[order]\n",
        "    train_labels = np.int32(labels[0:n//2])\n",
        "    i1 = n//2\n",
        "    i2 = n*3//5\n",
        "    train_dat=data[0:i1,:,:,:]\n",
        "    train_labels=np.int32(labels[0:i1])\n",
        "    val_dat=data[i1:i2]\n",
        "    val_labels=np.int32(labels[i1:i2])\n",
        "    test_dat=data[i2:n]\n",
        "    test_labels=np.int32(labels[i2:n])\n",
        "    return (train_dat, train_labels), (val_dat, val_labels), (test_dat, test_labels)\n",
        "\n",
        "def get_onedigit_data(shuffle=False):\n",
        "    (x_train,y_train), (x_val,y_val), (x_test,y_test) = get_iso_digits_helper(shuffle)\n",
        "    img_rows, img_cols = 85,45\n",
        "\n",
        "    if K.image_data_format() == 'channels_first': \n",
        "        x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols) \n",
        "        x_val = x_val.reshape(x_val.shape[0], 1, img_rows, img_cols) \n",
        "        x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols) \n",
        "        input_shape = (1, img_rows, img_cols) \n",
        "    else: \n",
        "        x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1) \n",
        "        x_val = x_val.reshape(x_val.shape[0], img_rows, img_cols, 1) \n",
        "        x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1) \n",
        "        input_shape = (img_rows, img_cols, 1) \n",
        "\n",
        "    x_train = x_train.astype('float32') \n",
        "    x_val = x_val.astype('float32') \n",
        "    x_test = x_test.astype('float32') \n",
        "\n",
        "    y_train = keras.utils.to_categorical(y_train, 10) \n",
        "    y_val = keras.utils.to_categorical(y_val, 10) \n",
        "    y_test = keras.utils.to_categorical(y_test, 10)\n",
        "    return (x_train,y_train), (x_val,y_val), (x_test,y_test), input_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiQnXc1U-mOS"
      },
      "source": [
        "### Compiling and running the model\n",
        "\n",
        "We start by using the exact same model as we did at the start of the project. This model here was the inspiration for the model we used up there."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fa0opRFY-mOS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60f5b57e-3ca2-4d11-aa07-e61073e99bb8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/12\n",
            "72/72 [==============================] - 4s 29ms/step - loss: 1.0680 - accuracy: 0.6535 - val_loss: 0.2511 - val_accuracy: 0.9361\n",
            "Epoch 2/12\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.1896 - accuracy: 0.9406 - val_loss: 0.0291 - val_accuracy: 0.9992\n",
            "Epoch 3/12\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0585 - accuracy: 0.9825 - val_loss: 0.0070 - val_accuracy: 1.0000\n",
            "Epoch 4/12\n",
            "72/72 [==============================] - 3s 36ms/step - loss: 0.0470 - accuracy: 0.9853 - val_loss: 0.0040 - val_accuracy: 1.0000\n",
            "Epoch 5/12\n",
            "72/72 [==============================] - 2s 32ms/step - loss: 0.0252 - accuracy: 0.9945 - val_loss: 0.0011 - val_accuracy: 1.0000\n",
            "Epoch 6/12\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0212 - accuracy: 0.9945 - val_loss: 3.1521e-04 - val_accuracy: 1.0000\n",
            "Epoch 7/12\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0233 - accuracy: 0.9934 - val_loss: 8.6991e-04 - val_accuracy: 1.0000\n",
            "Epoch 8/12\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0161 - accuracy: 0.9952 - val_loss: 8.0320e-05 - val_accuracy: 1.0000\n",
            "Epoch 9/12\n",
            "72/72 [==============================] - 2s 23ms/step - loss: 0.0127 - accuracy: 0.9961 - val_loss: 5.9579e-05 - val_accuracy: 1.0000\n",
            "Epoch 10/12\n",
            "72/72 [==============================] - 2s 28ms/step - loss: 0.0110 - accuracy: 0.9963 - val_loss: 8.9372e-05 - val_accuracy: 1.0000\n",
            "Epoch 11/12\n",
            "72/72 [==============================] - 2s 25ms/step - loss: 0.0140 - accuracy: 0.9950 - val_loss: 8.8916e-05 - val_accuracy: 1.0000\n",
            "Epoch 12/12\n",
            "72/72 [==============================] - 2s 24ms/step - loss: 0.0080 - accuracy: 0.9974 - val_loss: 1.5013e-05 - val_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0e547eac10>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "## Loading the data\n",
        "(x1_train,y1_train), (x1_val,y1_val), (x1_test,y1_test), input1_shape = get_onedigit_data(shuffle=True)\n",
        "\n",
        "## Constructing the model\n",
        "modelIso = Sequential() \n",
        "modelIso.add(Conv2D(32, kernel_size = (3, 3), activation = 'relu', input_shape = input1_shape)) \n",
        "modelIso.add(Conv2D(64, (3, 3), activation = 'relu')) \n",
        "modelIso.add(MaxPooling2D(pool_size = (2, 2))) \n",
        "modelIso.add(Dropout(0.25))\n",
        "modelIso.add(Flatten()) \n",
        "modelIso.add(Dense(128, activation = 'relu')) \n",
        "modelIso.add(Dropout(0.5)) \n",
        "modelIso.add(Dense(10, activation = 'softmax'))\n",
        "\n",
        "## Compiling and training the model\n",
        "modelIso.compile(loss = keras.losses.categorical_crossentropy, \n",
        "   optimizer = 'Adam', metrics = ['accuracy'])\n",
        "modelIso.fit(x1_train, y1_train, batch_size = 64, epochs = 12, verbose = 1, validation_data = (x1_test, y1_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In just 12 epochs, we are able to achieve a validation accuracy of 100%. That is absolutely incredible and gives credence to the idea that if we isolated the last digit, we could've achieved 100% validation accuracy on it as well. Because the last digit's distribution is roughly uniform, we would not be missing additional context from the other 4 digits."
      ],
      "metadata": {
        "id": "eJ85YF-izpcg"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9IqPBg0S-mOS"
      },
      "source": [
        "# Problem 3\n",
        "\n",
        "In this section we explore the effectiveness of our model on deformed data. \n",
        "\n",
        "This is really interesting because we're effectively testing if our model can account for real world conditions like the camera mount sagging, the lighting in the basement changing, etc."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A8g8hfkO-mOS"
      },
      "outputs": [],
      "source": [
        "deformed_data = np.float32(np.load(datadir+'data/gas_data.npy'))/255.\n",
        "deformed_labels = np.float32(np.load(datadir+'data/gas_labels.npy'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xnmI-6Iw-mOT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b52f46fd-5e15-41ce-c6f2-a407971098f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have a 5 digit accuracy of 0.9963761551005617\n",
            "The number of times each digit was wrong: [ 0  1  0 39]\n"
          ]
        }
      ],
      "source": [
        "wrong = np.array([0,0,0,0])\n",
        "all_correct = True\n",
        "n = deformed_data.shape[0]\n",
        "num_correct = 0\n",
        "\n",
        "for ii in range(n):\n",
        "    ## Generate prediction\n",
        "    data_vec = deformed_data[ii].reshape(1,85,195,1)\n",
        "    prediction = model.predict(data_vec,verbose=0)\n",
        "    ## Iterate over all digits predicted\n",
        "    for di in range(4):\n",
        "        predicted_label = np.argmax(prediction[di])\n",
        "        real_label = deformed_labels[ii][di+1]\n",
        "        ## If ever wrong, write down which digit and note that\n",
        "        if predicted_label != real_label:\n",
        "            wrong[di] += 1\n",
        "            all_correct = False\n",
        "    ## If we're still right, move on!\n",
        "    if all_correct:\n",
        "        num_correct += 1\n",
        "    all_correct = True\n",
        "print(\"We have a 5 digit accuracy of\",num_correct/n)\n",
        "print(\"The number of times each digit was wrong:\",wrong)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkXEJW4B-mOT"
      },
      "source": [
        "That is significantly better than I expected. It seems like the main issue is with the fifth digit since we seem to be performing mostly fine on the original data. It's important to point out that the non-deformed equivalents that were in our training set are a part of this set we're testing. \n",
        "\n",
        "Our results suggest convolution is somewhat robust to minor deformation, and our last digit has the most error because it already had the most error (likely due to it being the most uniform) and now that gets exacerbated.\n",
        "\n",
        "In theory it would be nice to build our model to be more deformation-proof by including deformed data in our training set, and in the real world I absolutely would do that and I have experience doing that from my internship at LiquidX. \n",
        "\n",
        "In practice I think this results are incredibly satisfactory and getting the the least significant digit wrong in this specific context (reading a gas meter) < 0.004% of the time doesn't have major implications anyways."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "71f4cc5eb07bc0d3ebcedfacc2ab6af50243ce67f8422c9aca860a9f159ae015"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}